{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.io\n",
    "import scipy.sparse as sp\n",
    "import csv\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from helpers import calculate_mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.1 Load and prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the Data\n",
    "`ratings` is a sparse matrix in the shape of (num_items, num_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of items: 1682, number of users: 943\n"
     ]
    }
   ],
   "source": [
    "from helpers import load_data, preprocess_data\n",
    "\n",
    "DATA_PATH = '../data/'\n",
    "PREDICTION_PATH = '../data/predictions/'\n",
    "#ratings = load_data('{dp}data_train.csv'.format(dp=DATA_PATH))\n",
    "ratings = load_data('{dp}movielens100k.csv'.format(dp=DATA_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the number of ratings per movie and user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkCxBGWOMCaT/B2ibxC1SbkMTAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f64d97426a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min # of items per user = 20, min # of users per item = 1.\n"
     ]
    }
   ],
   "source": [
    "from plots import plot_raw_data\n",
    "\n",
    "num_items_per_user, num_users_per_item = plot_raw_data(ratings)\n",
    "\n",
    "print(\"min # of items per user = {}, min # of users per item = {}.\".format(\n",
    "        min(num_items_per_user), min(num_users_per_item)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the data into a train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_data(ratings, num_items_per_user, num_users_per_item,\n",
    "               min_num_ratings, p_test=0.1, verbose=False):\n",
    "    \"\"\"split the ratings to training data and test data.\n",
    "    Args:\n",
    "        min_num_ratings: \n",
    "            all users and items we keep must have at least min_num_ratings per user and per item. \n",
    "    \"\"\"\n",
    "    # set seed\n",
    "    np.random.seed(988)\n",
    "    \n",
    "    # select user and item based on the condition.\n",
    "    valid_users = np.where(num_items_per_user >= min_num_ratings)[0]\n",
    "    valid_items = np.where(num_users_per_item >= min_num_ratings)[0]\n",
    "    valid_ratings = ratings[valid_items, :][:, valid_users]\n",
    "    \n",
    "    # LIL is a convenient format for constructing sparse matrices\n",
    "    train = sp.lil_matrix(valid_ratings.shape)\n",
    "    test = sp.lil_matrix(valid_ratings.shape)\n",
    "    \n",
    "    valid_ratings_i, valid_ratings_u, valid_ratings_v = sp.find(valid_ratings)\n",
    "    valid_ratings_p_idx = np.random.permutation(range(len(valid_ratings_i)))\n",
    "    \n",
    "    n_test = int(p_test*len(valid_ratings_i))\n",
    "    \n",
    "    for idx in valid_ratings_p_idx[:n_test]:\n",
    "        test[valid_ratings_i[idx], valid_ratings_u[idx]] = valid_ratings_v[idx]\n",
    "        \n",
    "    for idx in valid_ratings_p_idx[n_test:]:\n",
    "        train[valid_ratings_i[idx], valid_ratings_u[idx]] = valid_ratings_v[idx]\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Total number of nonzero elements in original data:{v}\".format(v=ratings.nnz))\n",
    "        print(\"Total number of nonzero elements in train data:{v}\".format(v=train.nnz))\n",
    "        print(\"Total number of nonzero elements in test data:{v}\".format(v=test.nnz))\n",
    "    \n",
    "    # convert to CSR for faster operations\n",
    "    return valid_ratings, train.tocsr(), test.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of nonzero elements in original data:99999\n",
      "Total number of nonzero elements in train data:88157\n",
      "Total number of nonzero elements in test data:9795\n"
     ]
    }
   ],
   "source": [
    "valid_ratings, train, test = split_data(ratings, num_items_per_user,\n",
    "    num_users_per_item, min_num_ratings=10, p_test=0.1, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read submission creation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of items: 10000, number of users: 1000\n"
     ]
    }
   ],
   "source": [
    "ratings_csr = ratings.tocsr()\n",
    "sample_submission = load_data('{dp}sample_submission.csv'.format(dp=DATA_PATH))\n",
    "sample_submission_csr = sample_submission.tocsr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.2 Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_division(a, b):\n",
    "    \"\"\"Computes element by element division.\n",
    "    If x/0 returns 0.\n",
    "    \"\"\"\n",
    "    # Raises error if vectors have different lengths\n",
    "    assert(len(a) == len(b))\n",
    "    \n",
    "    # Computes division\n",
    "    res = a.copy()\n",
    "    for i in range(len(a)):\n",
    "        if b[i] == 0:\n",
    "            res[i] = 0\n",
    "        else:\n",
    "            res[i] = a[i] / b[i]\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Baseline rating\n",
    "def baseline_rating(data):\n",
    "    \"\"\"Implements baseline method for a ratings matrix\n",
    "    using the global mean.\n",
    "    \"\"\"\n",
    "    # Compute global mean using training data\n",
    "    r_mean = data.sum() / data.getnnz()\n",
    "    \n",
    "    return r_mean\n",
    "\n",
    "\n",
    "# User or item specific effect\n",
    "def baseline_user_item_specific(data, mean, set_num=0):\n",
    "    \"\"\"Implements baseline method for a ratings matrix\n",
    "    using either the user or the item mean,\n",
    "    as indicated in parameter mean.\n",
    "    \"\"\"\n",
    "    if mean==\"user\":\n",
    "        flag = 1\n",
    "        inv_flag = 0\n",
    "    else:\n",
    "        flag = 0\n",
    "        inv_flag = 1\n",
    "\n",
    "    num = max(set_num, data.shape[flag])\n",
    "    \n",
    "    # Obtain r_demeaned (ratings minus global avg)\n",
    "    global_mean = baseline_rating(data)\n",
    "    r_demeaned = data.copy()\n",
    "    r_demeaned.data = (1.0 * r_demeaned.data) - global_mean\n",
    "    \n",
    "    # Compute means using training data\n",
    "    # get rows, columns and values for elements in r_demeaned\n",
    "    data_rcv = sp.find(r_demeaned)\n",
    "    # compute means\n",
    "    counts = np.bincount(data_rcv[flag], minlength=num)\n",
    "    sums = np.bincount(data_rcv[flag], weights=data_rcv[2], minlength=num)\n",
    "    means = compute_division(sums, counts)\n",
    "\n",
    "    return means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def demean_matrix(data, verbose=False):\n",
    "    \"\"\"Removes the global, user and item means from a matrix.\n",
    "    Returns the matrix and the computed means.\n",
    "    \"\"\"\n",
    "    num_items, num_users = data.shape\n",
    "    (rows, cols, vals) = sp.find(data)\n",
    "    \n",
    "    # Compute global, user and item means    \n",
    "    global_mean = baseline_rating(data)\n",
    "    item_means = baseline_user_item_specific(data, 'item')\n",
    "    user_means = baseline_user_item_specific(data, 'user')\n",
    "    \n",
    "    # Substract the baseline of each element in 'data'\n",
    "    train_vals = vals.copy()\n",
    "    train_vals = 1.0 * train_vals\n",
    "    \n",
    "    baselines = np.array([(global_mean + item_means[i] + user_means[u])\n",
    "        for (i, u) in zip(rows, cols)])\n",
    "    train_vals -= baselines\n",
    "\n",
    "    # Get matrix\n",
    "    r_demeaned = sp.csr_matrix((train_vals, (rows, cols)),\n",
    "        shape=(num_items, num_users))\n",
    "    \n",
    "    if verbose:\n",
    "        print('---------------------------------------------')\n",
    "        print('          Completed demean_matrix!           ')\n",
    "        print('---------------------------------------------')\n",
    "    \n",
    "    return r_demeaned, global_mean, user_means, item_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def demean_test_matrix(data, global_mean, item_means, user_means,\n",
    "    verbose=False):\n",
    "    \"\"\"Removes the global, user and item means from a matrix.\n",
    "    Returns the matrix and the computed means.\n",
    "    \"\"\"\n",
    "    num_items, num_users = data.shape\n",
    "    (rows, cols, vals) = sp.find(data)\n",
    "    \n",
    "    # Substract the baseline of each element in 'data'\n",
    "    train_vals = vals.copy()\n",
    "    train_vals = 1.0 * train_vals\n",
    "    \n",
    "    baselines = np.array([(global_mean + item_means[i] + user_means[u])\n",
    "        for (i, u) in zip(rows, cols)])\n",
    "    train_vals -= baselines\n",
    "\n",
    "    # Get matrix\n",
    "    r_demeaned = sp.csr_matrix((train_vals, (rows, cols)),\n",
    "        shape=(num_items, num_users))\n",
    "    \n",
    "    if verbose:\n",
    "        print('---------------------------------------------')\n",
    "        print('          Completed demean_matrix!           ')\n",
    "        print('---------------------------------------------')\n",
    "    return r_demeaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_MF(data, k):\n",
    "    \"\"\"Initializes parameters for Matrix Factorization.\n",
    "    Assumes 'data' matrix is already demeaned.\n",
    "    \"\"\"      \n",
    "    np.random.seed(988)\n",
    "    num_items, num_users = data.shape\n",
    "    u_features = np.random.rand(num_users, k)\n",
    "    i_features = np.random.rand(num_items, k)\n",
    "    return u_features, i_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the cost by the method of matrix factorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_error(data, u_features, i_features, nz):\n",
    "    \"\"\"Compute RMSE for prediction of nonzero elements.\"\"\"\n",
    "    preds = np.array([(u_features[u,:].dot(i_features[i,:]))\n",
    "        for (i, u) in nz])\n",
    "    vals = np.array([data[i,u] for (i,u) in nz])\n",
    "    mse = calculate_mse(vals, preds)  \n",
    "    rmse = np.sqrt(mse / len(vals))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mf_SGD(r_demeaned, nz_train, test_r_demeaned, nz_test, k=20, gamma=0.01, gamma_dec=1.2,\n",
    "    u_lambda=0.5, i_lambda=0.5, max_iter=None, int_vals=False, verbose=False, tol=1e-5,\n",
    "    init_u_features=None, init_i_features=None):\n",
    "    \"\"\"Compute matrix factorization by SGD.\n",
    "    Both 'data' and 'test_data' should be csr sparse matrices.\n",
    "    gamma_dec should be >=1\n",
    "    \"\"\"\n",
    "\n",
    "    #assert k <= min(data.shape), \"k must be smaller than the min dimension of 'data'\"\n",
    "    if (max_iter is None):\n",
    "        steps = 50\n",
    "    else:\n",
    "        steps = max_iter\n",
    "\n",
    "    # Set seed\n",
    "    np.random.seed(988)\n",
    "    \n",
    "    rand_u_features, rand_i_features = init_MF(r_demeaned, k)\n",
    "    \n",
    "    if (init_u_features is None):\n",
    "        u_features = rand_u_features\n",
    "    else:\n",
    "        u_features = init_u_features\n",
    "        \n",
    "    if (init_i_features is None):\n",
    "        i_features = rand_i_features\n",
    "    else:\n",
    "        i_features = init_i_features\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Starting matrix factorization with SGD...\")\n",
    "\n",
    "    rmse = 0\n",
    "    for step in range(steps):\n",
    "        # shuffle the training rating indices\n",
    "        np.random.seed(988)\n",
    "        np.random.shuffle(nz_train)\n",
    "        \n",
    "        # Reduce learning rate\n",
    "        gamma /= gamma_dec\n",
    "        \n",
    "        # Update item and user features\n",
    "        for i, u in nz_train:\n",
    "            i_f = i_features[i,:]\n",
    "            u_f = u_features[u,:]\n",
    "            e = r_demeaned[i, u] - np.dot(u_f,i_f)\n",
    "            # Obtain gradient\n",
    "            i_grad = e * u_f - i_lambda * i_f\n",
    "            u_grad = e * i_f - u_lambda * u_f\n",
    "            # Update user and item features\n",
    "            i_features[i,:] += gamma * i_grad\n",
    "            u_features[u,:] += gamma * u_grad\n",
    "        \n",
    "        rmse_old = rmse\n",
    "        rmse = compute_error(r_demeaned, u_features, i_features, nz_train)\n",
    "        print(\"{} - train_RMSE: {}.\".format(step, rmse))\n",
    "\n",
    "        # evaluate the test error\n",
    "        test_rmse = compute_error(test_r_demeaned, u_features, i_features, nz_test)\n",
    "        print(\"test RMSE: {}.\".format(test_rmse))\n",
    "        \n",
    "        if(rmse_old - rmse < 0):\n",
    "            gamma_dec += .15\n",
    "            gamma /= gamma_dec\n",
    "        elif(abs(rmse_old - rmse) <= tol):\n",
    "            break\n",
    "\n",
    "    return i_features, u_features, rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try different parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demean matrix and get feature vectors\n",
    "r_demeaned, global_mean, user_means, item_means = demean_matrix(train, verbose=False)\n",
    "\n",
    "# Get non-zero elements\n",
    "nz_row, nz_col = train.nonzero()\n",
    "nz_train = list(zip(nz_row, nz_col))\n",
    "\n",
    "test_r_demeaned = demean_test_matrix(test, global_mean, item_means,\n",
    "    user_means, verbose=False)\n",
    "nz_row, nz_col = test.nonzero()\n",
    "nz_test = list(zip(nz_row, nz_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_k = {}\n",
    "i=0\n",
    "for k in range(10, 110, 10):\n",
    "    print('----------------------------')\n",
    "    print('       k={}                    '.format(k))\n",
    "    print('----------------------------')\n",
    "    i_features, u_features, rmse = compute_mf_SGD(r_demeaned, nz_train, test_r_demeaned, nz_test, k=k, int_vals=True, verbose=True)\n",
    "    results_k[i]=(k, i_features, u_features, rmse)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_gamma = {}\n",
    "i=0\n",
    "for gamma in np.logspace(-3, -1, 10):\n",
    "    print('----------------------------')\n",
    "    print('       gamma={}                    '.format(gamma))\n",
    "    print('----------------------------')\n",
    "    i_features, u_features, rmse = compute_mf_SGD(r_demeaned, nz_train, test_r_demeaned, nz_test, gamma=gamma, int_vals=True, verbose=True)\n",
    "    results_gamma[i]=(gamma, i_features, u_features, rmse)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(988)\n",
    "results_u_lambda = {}\n",
    "i=0\n",
    "for u_lambda in np.linspace(0,2,10):\n",
    "    print('----------------------------')\n",
    "    print('       u_lambda={}                    '.format(u_lambda))\n",
    "    print('----------------------------')\n",
    "    i_features, u_features, rmse = compute_mf_SGD(r_demeaned, nz_train, test_r_demeaned, nz_test, u_lambda=u_lambda, int_vals=True, verbose=True)\n",
    "    results_u_lambda[i]=(u_lambda, i_features, u_features, rmse)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_i_lambda = {}\n",
    "i=0\n",
    "i_features=None\n",
    "u_features=None\n",
    "for i_lambda in np.linspace(0,2,10):\n",
    "    print('----------------------------')\n",
    "    print('       i_lambda={}                    '.format(i_lambda))\n",
    "    print('----------------------------')\n",
    "    i_features, u_features, rmse = compute_mf_SGD(r_demeaned, nz_train, test_r_demeaned,\n",
    "        nz_test, i_lambda=i_lambda, int_vals=True, verbose=True, init_i_features=i_features,\n",
    "        init_u_features=u_features)\n",
    "    results_i_lambda[i]=(i_lambda, i_features, u_features, rmse)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "u_lambda_center = 2.0\n",
    "i_lambda_center = 0.4\n",
    "results_lambda = {}\n",
    "results_lambda_mat = np.zeros((5,5))\n",
    "i=0\n",
    "l=0\n",
    "m=0\n",
    "i_features=None\n",
    "u_features=None\n",
    "for i_lambda in np.linspace(i_lambda_center-.2, i_lambda_center+.2, 5):\n",
    "    m=0\n",
    "    for u_lambda in np.linspace(u_lambda_center-.3, u_lambda_center+.3, 5):\n",
    "        print('----------------------------')\n",
    "        print(' i_lambda={}    u_lambda={}  '.format(i_lambda, u_lambda))\n",
    "        print('----------------------------')\n",
    "        i_features, u_features, rmse = compute_mf_SGD(r_demeaned, nz_train, test_r_demeaned,\n",
    "            nz_test, i_lambda=i_lambda, u_lambda=u_lambda, int_vals=True, verbose=True, init_i_features=i_features,\n",
    "            init_u_features=u_features)\n",
    "        results_lambda[i]=(i_lambda, u_lambda, i_features, u_features, rmse)\n",
    "        results_lambda_mat[l,m]=rmse\n",
    "        m+=1\n",
    "        i+=1\n",
    "    l+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting matrix factorization with SGD...\n",
      "0 - train_RMSE: 0.9319571454308242.\n",
      "test RMSE: 0.9665100526794229.\n",
      "1 - train_RMSE: 0.9312761003886793.\n",
      "test RMSE: 0.96638297428526.\n",
      "2 - train_RMSE: 0.9307966970701645.\n",
      "test RMSE: 0.9663056551165.\n",
      "3 - train_RMSE: 0.930444498826798.\n",
      "test RMSE: 0.9662435940744988.\n",
      "4 - train_RMSE: 0.9301826426210329.\n",
      "test RMSE: 0.9661981024687464.\n",
      "5 - train_RMSE: 0.9299872733334507.\n",
      "test RMSE: 0.9661662901972351.\n",
      "6 - train_RMSE: 0.9298414342627287.\n",
      "test RMSE: 0.966142948024491.\n",
      "7 - train_RMSE: 0.9297326509507978.\n",
      "test RMSE: 0.96612425520987.\n",
      "8 - train_RMSE: 0.9296515963453335.\n",
      "test RMSE: 0.9661100084477544.\n",
      "9 - train_RMSE: 0.9295912796492761.\n",
      "test RMSE: 0.9660996463479206.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-6bc03e81bb7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m i_features, u_features, rmse = compute_mf_SGD(r_demeaned, nz_train, test_r_demeaned,\n\u001b[1;32m      2\u001b[0m     \u001b[0mnz_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_lambda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_lambda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint_vals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     init_i_features=i_features, init_u_features=u_features)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-41-40c1f6153cd5>\u001b[0m in \u001b[0;36mcompute_mf_SGD\u001b[0;34m(r_demeaned, nz_train, test_r_demeaned, nz_test, k, gamma, gamma_dec, u_lambda, i_lambda, max_iter, int_vals, verbose, tol, init_u_features, init_i_features)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr_demeaned\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_f\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;31m# Obtain gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0mi_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mu_f\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mi_lambda\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mi_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m             \u001b[0mu_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mi_f\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mu_lambda\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mu_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;31m# Update user and item features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "i_features, u_features, rmse = compute_mf_SGD(r_demeaned, nz_train, test_r_demeaned,\n",
    "    nz_test, i_lambda=0, u_lambda=0, int_vals=True, verbose=True,\n",
    "    init_i_features=i_features, init_u_features=u_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting matrix factorization with SGD...\n",
      "0 - train_RMSE: 0.9340167954020437.\n",
      "test RMSE: 0.9669795994027292.\n",
      "1 - train_RMSE: 0.9340276008467745.\n",
      "test RMSE: 0.9669488820057074.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-8f357e49a2f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mnz_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_lambda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_lambda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint_vals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma_dec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     init_i_features=i_features, init_u_features=u_features)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-41-40c1f6153cd5>\u001b[0m in \u001b[0;36mcompute_mf_SGD\u001b[0;34m(r_demeaned, nz_train, test_r_demeaned, nz_test, k, gamma, gamma_dec, u_lambda, i_lambda, max_iter, int_vals, verbose, tol, init_u_features, init_i_features)\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mi_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mu_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr_demeaned\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_f\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0;31m# Obtain gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mi_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mu_f\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mi_lambda\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mi_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/sparse/csr.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0;31m# [i, j]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misintlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_single_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m             \u001b[0;31m# [i, 1:2]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36m_get_single_element\u001b[0;34m(self, row, col)\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"index out of bounds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mmajor_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminor_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_swap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0;31m# TODO make use of sorted indices (if present)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/sparse/csr.py\u001b[0m in \u001b[0;36m_swap\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;31m# these functions are used by the parent class (_cs_matrix)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;31m# to remove redudancy between csc_matrix and csr_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m_swap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m         \"\"\"swap the members of x if this is a column-oriented matrix\n\u001b[1;32m    233\u001b[0m         \"\"\"\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "i_features, u_features, rmse = compute_mf_SGD(r_demeaned, nz_train, test_r_demeaned,\n",
    "    nz_test, i_lambda=0.2, u_lambda=2.0, int_vals=True, verbose=True,\n",
    "    gamma=.01, gamma_dec=1.2,\n",
    "    init_i_features=i_features, init_u_features=u_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting matrix factorization with SGD...\n",
      "0 - train_RMSE: 0.9343196766290522.\n",
      "test RMSE: 0.967031068535483.\n",
      "1 - train_RMSE: 0.9343195637013358.\n",
      "test RMSE: 0.9670315909074707.\n"
     ]
    }
   ],
   "source": [
    "i_features, u_features, rmse = compute_mf_SGD(r_demeaned, nz_train, test_r_demeaned,\n",
    "    nz_test, i_lambda=0.2, u_lambda=2.0, int_vals=True, verbose=True,\n",
    "    gamma=.3, gamma_dec=1.9,\n",
    "    init_i_features=i_features, init_u_features=u_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_features, u_features, rmse = compute_mf_SGD(r_demeaned, nz_train, test_r_demeaned,\n",
    "    nz_test, i_lambda=0.4, u_lambda=2.0, int_vals=True, verbose=True,\n",
    "    init_i_features=i_features, init_u_features=u_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i_features, u_features, rmse = compute_mf_SGD(r_demeaned, nz_train, test_r_demeaned,\n",
    "    nz_test, i_lambda=0.6, u_lambda=2.0, int_vals=True, verbose=True,\n",
    "    init_i_features=i_features, init_u_features=u_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Demean matrix and get feature vectors\n",
    "r_demeaned, global_mean, user_means, item_means = demean_matrix(ratings_csr, verbose=False)\n",
    "\n",
    "# Get non-zero elements\n",
    "nz_row, nz_col = ratings_csr.nonzero()\n",
    "nz_train = list(zip(nz_row, nz_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_mf_SGD(r_demeaned, nz_train, k=20, gamma=0.01, gamma_dec=1.2,\n",
    "    u_lambda=0.5, i_lambda=0.5, max_iter=None, int_vals=False, verbose=False, tol=1e-6):\n",
    "    \"\"\"Compute matrix factorization by SGD.\n",
    "    'data' should be a csr sparse matrices.\n",
    "    gamma_dec should be >=1\n",
    "    \"\"\"\n",
    "\n",
    "    #assert k <= min(data.shape), \"k must be smaller than the min dimension of 'data'\"\n",
    "    if (max_iter is None):\n",
    "        steps = 50\n",
    "    else:\n",
    "        steps = max_iter\n",
    "\n",
    "    # Set seed\n",
    "    np.random.seed(988)\n",
    "\n",
    "    u_features, i_features = init_MF(r_demeaned, k)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Starting matrix factorization with SGD...\")\n",
    "\n",
    "    rmse = 0\n",
    "    for step in range(steps):\n",
    "        # shuffle the training rating indices\n",
    "        np.random.shuffle(nz_train)\n",
    "        \n",
    "        # Reduce learning rate\n",
    "        gamma /= gamma_dec\n",
    "        \n",
    "        # Update item and user features\n",
    "        for i, u in nz_train:\n",
    "            i_f = i_features[i,:]\n",
    "            u_f = u_features[u,:]\n",
    "            e = r_demeaned[i, u] - np.dot(u_f,i_f)\n",
    "            # Obtain gradient\n",
    "            i_grad = e * u_f - i_lambda * i_f\n",
    "            u_grad = e * i_f - u_lambda * u_f\n",
    "            # Update user and item features\n",
    "            i_features[i,:] += gamma * i_grad\n",
    "            u_features[u,:] += gamma * u_grad\n",
    "        \n",
    "        rmse_old = rmse\n",
    "        rmse = compute_error(r_demeaned, u_features, i_features, nz_train)\n",
    "        print(\"{} - train_RMSE: {}.\".format(step, rmse))\n",
    "        \n",
    "        if(abs(rmse_old - rmse) <= tol):\n",
    "            break\n",
    "\n",
    "    return i_features, u_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_features, u_features = compute_mf_SGD(r_demeaned, nz_train, int_vals=False, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(test_rows, test_cols, test_vals) = sp.find(sample_submission_csr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('{dp}{fn}.csv'.format(dp=PREDICTION_PATH, fn='test_rnd'), 'w') as csvfile:\n",
    "    fieldnames = ['Id', 'Prediction']\n",
    "    writer = csv.DictWriter(csvfile, delimiter=\",\", fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for (i, u) in zip(test_rows, test_cols):\n",
    "        interaction = np.array([(u_features[u,:].dot(i_features[i,:]))\n",
    "        baseline = global_mean + user_means[u] + item_means[i]\n",
    "        pred_i_u = interaction + baseline\n",
    "        writer.writerow({'Id':'r{r}_c{c}'.format(r=i+1,c=u+1),'Prediction':pred_i_u})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
