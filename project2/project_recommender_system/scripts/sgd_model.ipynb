{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.io\n",
    "import scipy.sparse as sp\n",
    "import csv\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from helpers import calculate_mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.1 Load and prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the Data\n",
    "`ratings` is a sparse matrix in the shape of (num_items, num_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of items: 10000, number of users: 1000\n"
     ]
    }
   ],
   "source": [
    "from helpers import load_data, preprocess_data\n",
    "\n",
    "DATA_PATH = '../data/'\n",
    "PREDICTION_PATH = '../data/predictions/'\n",
    "ratings = load_data('{dp}data_train.csv'.format(dp=DATA_PATH))\n",
    "#ratings = load_data('{dp}movielens100k.csv'.format(dp=DATA_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the number of ratings per movie and user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1qnOytJRgYgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe4e863e748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min # of items per user = 8, min # of users per item = 3.\n"
     ]
    }
   ],
   "source": [
    "from plots import plot_raw_data\n",
    "\n",
    "num_items_per_user, num_users_per_item = plot_raw_data(ratings)\n",
    "\n",
    "print(\"min # of items per user = {}, min # of users per item = {}.\".format(\n",
    "        min(num_items_per_user), min(num_users_per_item)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the data into a train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(ratings, num_items_per_user, num_users_per_item,\n",
    "               min_num_ratings, p_test=0.1, verbose=False):\n",
    "    \"\"\"split the ratings to training data and test data.\n",
    "    Args:\n",
    "        min_num_ratings: \n",
    "            all users and items we keep must have at least min_num_ratings per user and per item. \n",
    "    \"\"\"\n",
    "    # set seed\n",
    "    np.random.seed(988)\n",
    "    \n",
    "    # select user and item based on the condition.\n",
    "    valid_users = np.where(num_items_per_user >= min_num_ratings)[0]\n",
    "    valid_items = np.where(num_users_per_item >= min_num_ratings)[0]\n",
    "    valid_ratings = ratings[valid_items, :][:, valid_users]\n",
    "    \n",
    "    # LIL is a convenient format for constructing sparse matrices\n",
    "    train = sp.lil_matrix(valid_ratings.shape)\n",
    "    test = sp.lil_matrix(valid_ratings.shape)\n",
    "    \n",
    "    valid_ratings_i, valid_ratings_u, valid_ratings_v = sp.find(valid_ratings)\n",
    "    valid_ratings_p_idx = np.random.permutation(range(len(valid_ratings_i)))\n",
    "    \n",
    "    n_test = int(p_test*len(valid_ratings_i))\n",
    "    \n",
    "    for idx in valid_ratings_p_idx[:n_test]:\n",
    "        test[valid_ratings_i[idx], valid_ratings_u[idx]] = valid_ratings_v[idx]\n",
    "        \n",
    "    for idx in valid_ratings_p_idx[n_test:]:\n",
    "        train[valid_ratings_i[idx], valid_ratings_u[idx]] = valid_ratings_v[idx]\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Total number of nonzero elements in original data:{v}\".format(v=ratings.nnz))\n",
    "        print(\"Total number of nonzero elements in train data:{v}\".format(v=train.nnz))\n",
    "        print(\"Total number of nonzero elements in test data:{v}\".format(v=test.nnz))\n",
    "    \n",
    "    # convert to CSR for faster operations\n",
    "    return valid_ratings, train.tocsr(), test.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of nonzero elements in original data:1176952\n",
      "Total number of nonzero elements in train data:1055804\n",
      "Total number of nonzero elements in test data:117311\n"
     ]
    }
   ],
   "source": [
    "valid_ratings, train, test = split_data(ratings, num_items_per_user,\n",
    "    num_users_per_item, min_num_ratings=25, p_test=0.1, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read submission creation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of items: 10000, number of users: 1000\n"
     ]
    }
   ],
   "source": [
    "ratings_csr = ratings.tocsr()\n",
    "sample_submission = load_data('{dp}sample_submission.csv'.format(dp=DATA_PATH))\n",
    "sample_submission_csr = sample_submission.tocsr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.2 Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_division(a, b):\n",
    "    \"\"\"Computes element by element division.\n",
    "    If x/0 returns 0.\n",
    "    \"\"\"\n",
    "    # Raises error if vectors have different lengths\n",
    "    assert(len(a) == len(b))\n",
    "    \n",
    "    # Computes division\n",
    "    res = a.copy()\n",
    "    for i in range(len(a)):\n",
    "        if b[i] == 0:\n",
    "            res[i] = 0\n",
    "        else:\n",
    "            res[i] = a[i] / b[i]\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Baseline rating\n",
    "def baseline_rating(data):\n",
    "    \"\"\"Implements baseline method for a ratings matrix\n",
    "    using the global mean.\n",
    "    \"\"\"\n",
    "    # Compute global mean using training data\n",
    "    r_mean = data.sum() / data.getnnz()\n",
    "    \n",
    "    return r_mean\n",
    "\n",
    "\n",
    "# User or item specific effect\n",
    "def baseline_user_item_specific(data, mean, set_num=0):\n",
    "    \"\"\"Implements baseline method for a ratings matrix\n",
    "    using either the user or the item mean,\n",
    "    as indicated in parameter mean.\n",
    "    \"\"\"\n",
    "    if mean==\"user\":\n",
    "        flag = 1\n",
    "        inv_flag = 0\n",
    "    else:\n",
    "        flag = 0\n",
    "        inv_flag = 1\n",
    "\n",
    "    num = max(set_num, data.shape[flag])\n",
    "    \n",
    "    # Obtain r_demeaned (ratings minus global avg)\n",
    "    global_mean = baseline_rating(data)\n",
    "    r_demeaned = data.copy()\n",
    "    r_demeaned.data = (1.0 * r_demeaned.data) - global_mean\n",
    "    \n",
    "    # Compute means using training data\n",
    "    # get rows, columns and values for elements in r_demeaned\n",
    "    data_rcv = sp.find(r_demeaned)\n",
    "    # compute means\n",
    "    counts = np.bincount(data_rcv[flag], minlength=num)\n",
    "    sums = np.bincount(data_rcv[flag], weights=data_rcv[2], minlength=num)\n",
    "    means = compute_division(sums, counts)\n",
    "\n",
    "    return means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demean_matrix(data, verbose=False):\n",
    "    \"\"\"Removes the global, user and item means from a matrix.\n",
    "    Returns the matrix and the computed means.\n",
    "    \"\"\"\n",
    "    num_items, num_users = data.shape\n",
    "    (rows, cols, vals) = sp.find(data)\n",
    "    \n",
    "    # Compute global, user and item means    \n",
    "    global_mean = baseline_rating(data)\n",
    "    item_means = baseline_user_item_specific(data, 'item')\n",
    "    user_means = baseline_user_item_specific(data, 'user')\n",
    "    \n",
    "    # Substract the baseline of each element in 'data'\n",
    "    train_vals = vals.copy()\n",
    "    train_vals = 1.0 * train_vals\n",
    "    \n",
    "    baselines = np.array([(global_mean + item_means[i] + user_means[u])\n",
    "        for (i, u) in zip(rows, cols)])\n",
    "    train_vals -= baselines\n",
    "\n",
    "    # Get matrix\n",
    "    r_demeaned = sp.csr_matrix((train_vals, (rows, cols)),\n",
    "        shape=(num_items, num_users))\n",
    "    \n",
    "    if verbose:\n",
    "        print('---------------------------------------------')\n",
    "        print('          Completed demean_matrix!           ')\n",
    "        print('---------------------------------------------')\n",
    "    \n",
    "    return r_demeaned, global_mean, user_means, item_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demean_test_matrix(data, global_mean, item_means, user_means,\n",
    "    verbose=False):\n",
    "    \"\"\"Removes the global, user and item means from a matrix.\n",
    "    Returns the matrix and the computed means.\n",
    "    \"\"\"\n",
    "    num_items, num_users = data.shape\n",
    "    (rows, cols, vals) = sp.find(data)\n",
    "    \n",
    "    # Substract the baseline of each element in 'data'\n",
    "    train_vals = vals.copy()\n",
    "    train_vals = 1.0 * train_vals\n",
    "    \n",
    "    baselines = np.array([(global_mean + item_means[i] + user_means[u])\n",
    "        for (i, u) in zip(rows, cols)])\n",
    "    train_vals -= baselines\n",
    "\n",
    "    # Get matrix\n",
    "    r_demeaned = sp.csr_matrix((train_vals, (rows, cols)),\n",
    "        shape=(num_items, num_users))\n",
    "    \n",
    "    if verbose:\n",
    "        print('---------------------------------------------')\n",
    "        print('          Completed demean_matrix!           ')\n",
    "        print('---------------------------------------------')\n",
    "    return r_demeaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_MF(data, k):\n",
    "    \"\"\"Initializes parameters for Matrix Factorization.\n",
    "    Assumes 'data' matrix is already demeaned.\n",
    "    \"\"\"      \n",
    "    np.random.seed(988)\n",
    "    num_items, num_users = data.shape\n",
    "    u_features = np.random.rand(num_users, k)\n",
    "    i_features = np.random.rand(num_items, k)\n",
    "    return u_features, i_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the cost by the method of matrix factorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_error(data, u_features, i_features, nz):\n",
    "    \"\"\"Compute RMSE for prediction of nonzero elements.\"\"\"\n",
    "    preds = np.array([(u_features[u,:].dot(i_features[i,:]))\n",
    "        for (i, u) in nz])\n",
    "    vals = np.array([data[i,u] for (i,u) in nz])\n",
    "    mse = calculate_mse(vals, preds)  \n",
    "    rmse = np.sqrt(mse / len(vals))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mf_SGD(r_demeaned, nz_train, test_r_demeaned, nz_test, k=20, gamma=0.01, gamma_dec=1.2,\n",
    "    u_lambda=0.5, i_lambda=0.5, max_iter=None, verbose=False, tol=5e-6,\n",
    "    init_u_features=None, init_i_features=None):\n",
    "    \"\"\"Compute matrix factorization by SGD.\n",
    "    Both 'data' and 'test_data' should be csr sparse matrices.\n",
    "    gamma_dec should be >1\n",
    "    \"\"\"\n",
    "\n",
    "    #assert k <= min(data.shape), \"k must be smaller than the min dimension of 'data'\"\n",
    "    if (max_iter is None):\n",
    "        steps = 20\n",
    "    else:\n",
    "        steps = max_iter\n",
    "\n",
    "    # Set seed\n",
    "    np.random.seed(988)\n",
    "    \n",
    "    rand_u_features, rand_i_features = init_MF(r_demeaned, k)\n",
    "    \n",
    "    if (init_u_features is None):\n",
    "        u_features = rand_u_features\n",
    "    else:\n",
    "        u_features = init_u_features\n",
    "        \n",
    "    if (init_i_features is None):\n",
    "        i_features = rand_i_features\n",
    "    else:\n",
    "        i_features = init_i_features\n",
    "\n",
    "    rmse_tr = 90\n",
    "    \n",
    "    for step in range(steps):\n",
    "        # shuffle the training rating indices\n",
    "        #np.random.shuffle(nz_train)\n",
    "        \n",
    "        # Update item and user features\n",
    "        for i, u in nz_train:\n",
    "            i_f = i_features[i,:]\n",
    "            u_f = u_features[u,:]\n",
    "            e = r_demeaned[i, u] - np.dot(u_f,i_f)\n",
    "            # Obtain gradient\n",
    "            i_grad = e * u_f - i_lambda * i_f\n",
    "            u_grad = e * i_f - u_lambda * u_f\n",
    "            # Update user and item features\n",
    "            i_features[i,:] += gamma * i_grad\n",
    "            u_features[u,:] += gamma * u_grad\n",
    "        \n",
    "        # Reduce learning rate\n",
    "        gamma /= gamma_dec    \n",
    "    \n",
    "        rmse_tr_old = rmse_tr\n",
    "        rmse_tr = compute_error(r_demeaned, u_features, i_features, nz_train)\n",
    "        print(\"{} - train_RMSE: {}.\".format(step, rmse_tr))\n",
    "\n",
    "        # evaluate the test error\n",
    "        np.random.shuffle(nz_test)\n",
    "        rmse_te = compute_error(test_r_demeaned, u_features, i_features, nz_test)\n",
    "        print(\"test RMSE: {}.\".format(rmse_te))\n",
    "    \n",
    "        if((rmse_tr - rmse_tr_old) > 4*tol):\n",
    "            print(\"Whoops!\")\n",
    "            break\n",
    "        if(abs(rmse_tr_old - rmse_tr) < tol):\n",
    "            break\n",
    "\n",
    "    return i_features, u_features, rmse_tr, rmse_te"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try different parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demean matrix and get feature vectors\n",
    "r_demeaned, global_mean, user_means, item_means = demean_matrix(train, verbose=False)\n",
    "\n",
    "# Get non-zero elements\n",
    "nz_row, nz_col = train.nonzero()\n",
    "nz_train = list(zip(nz_row, nz_col))\n",
    "\n",
    "test_r_demeaned = demean_test_matrix(test, global_mean, item_means,\n",
    "    user_means, verbose=False)\n",
    "\n",
    "nz_row, nz_col = test.nonzero()\n",
    "nz_test = list(zip(nz_row, nz_col))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "parameters = {'k':np.linspace(20,120,10), 'u_lambda':np.linspace(.2,2,10), 'i_lambda':np.linspace(0.2,1.5,10)}\n",
    "gamma_combs = {'gamma':np.logspace(-1,-3,10), 'gamma_dec':np.linspace(1.1,1.8,10)}\n",
    "\n",
    "results_dict = {}\n",
    "et=0\n",
    "i_f = None\n",
    "u_f = None\n",
    "np.random.seed(60)\n",
    "\n",
    "for execution in range(20):\n",
    "    i_f = None\n",
    "    u_f = None\n",
    "    k = int(np.random.choice(parameters['k']))\n",
    "    u_lambda = np.random.choice(parameters['u_lambda'])\n",
    "    i_lambda = np.random.choice(parameters['i_lambda'])\n",
    "\n",
    "    for trials in range(5):\n",
    "        gamma = gamma_combs['gamma'][trials]\n",
    "        gamma_dec = np.random.choice(gamma_combs['gamma_dec'])\n",
    "        print('----------------------')\n",
    "        print('k:{}  u_l:{}  i_l:{}'.format(k, u_lambda, i_lambda))\n",
    "        print('g:{}  g_d:{}'.format(gamma, gamma_dec))\n",
    "        print('----------------------')\n",
    "        i_f, u_f, rmse_tr, rmse_te = compute_mf_SGD(r_demeaned, nz_train, test_r_demeaned, nz_test,\n",
    "            verbose=True, #init_i_features=i_f, init_u_features=u_f,\n",
    "            k=k, i_lambda=i_lambda, u_lambda=u_lambda, gamma=gamma, gamma_dec=gamma_dec)\n",
    "\n",
    "        results_dict[et]={'k':k, 'u_lambda':u_lambda, 'i_lambda':i_lambda, 'gamma':gamma, 'gamma_dec':gamma_dec,\n",
    "                        'rmse_tr':rmse_tr, 'rmse_te':rmse_te, 'i_f':i_f, 'u_f':u_f}\n",
    "        et += 1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "parameters = [{'k':20, 'u_l':1.6, 'i_l':0.7777777777777779, 'g':0.015, 'g_d':[2.5, 3.5, 5.0]},\n",
    "              {'k':31, 'u_l':1.4, 'i_l':0.6333333333333333, 'g':0.02, 'g_d':[3.0, 4.0, 5.0]},\n",
    "              {'k':53, 'u_l':0.2, 'i_l':0.6333333333333333, 'g':0.04, 'g_d':[3.0, 4.0, 5.0]},\n",
    "              {'k':53, 'u_l':0.2, 'i_l':0.48888888888888893,'g':0.065, 'g_d':[3.0, 4.0, 5.0]},\n",
    "              {'k':53, 'u_l':0.6, 'i_l':1.2111111111111112, 'g':0.011, 'g_d':[2.2, 3.0, 4.0]},\n",
    "              {'k':64, 'u_l':0.2, 'i_l':1.3555555555555556, 'g':0.011, 'g_d':[2.0, 3.0, 4.0]},\n",
    "              {'k':64, 'u_l':0.2, 'i_l':1.3555555555555556, 'g':0.011, 'g_d':[2.0, 3.0, 4.0]},\n",
    "              {'k':64, 'u_l':0.8, 'i_l':0.48888888888888893,'g':0.045,'g_d':[2.0, 3.0, 4.0]},\n",
    "              {'k':64, 'u_l':1.8, 'i_l':0.6333333333333333, 'g':0.04, 'g_d':[2.0, 3.0, 4.0]},\n",
    "              {'k':64, 'u_l':1.8, 'i_l':0.9222222222222223, 'g':0.025,  'g_d':[2.0, 3.0, 4.0]},\n",
    "              {'k':75, 'u_l':1.8, 'i_l':0.2, 'g':0.045,'g_d':[1.6, 1.8, 2.1]},\n",
    "              {'k':75, 'u_l':1.8, 'i_l':0.2, 'g':0.01,'g_d':[1.2, 1.2555555555555555]},\n",
    "              {'k':86, 'u_l':1.4, 'i_l':0.34444444444444444,'g':0.007,'g_d':[1.67, 1.7222222222222223]},\n",
    "              {'k':97, 'u_l':1.4, 'i_l':0.6333333333333333, 'g':0.04, 'g_d':[1.8, 2.5, 3.0]},\n",
    "              {'k':108,'u_l':1.4, 'i_l':0.48888888888888893,'g':0.05, 'g_d':[1.8, 2.5, 3.0]},\n",
    "              {'k':108,'u_l':1.4, 'i_l':0.48888888888888893,'g':0.052, 'g_d':[1.8, 2.5, 3.0]},\n",
    "              {'k':108,'u_l':0.4, 'i_l':1.0666666666666667, 'g':0.022, 'g_d':[1.8, 2.5, 3.0]},\n",
    "              {'k':120,'u_l':0.8, 'i_l':1.5, 'g':0.014, 'g_d':[1.75, 1.9, 2.5]}]\n",
    "\n",
    "results_dict = {}\n",
    "et=0\n",
    "i_f = None\n",
    "u_f = None\n",
    "np.random.seed(60)\n",
    "\n",
    "for param_dict in parameters:\n",
    "    i_f = None\n",
    "    u_f = None\n",
    "    k = param_dict['k']\n",
    "    u_lambda = param_dict['u_l']\n",
    "    i_lambda = param_dict['i_l']\n",
    "    gamma = param_dict['g']\n",
    "\n",
    "    for gamma_dec in param_dict['g_d']:\n",
    "        print('----------------------')\n",
    "        print('k:{}  u_l:{}  i_l:{}'.format(k, u_lambda, i_lambda))\n",
    "        print('g:{}  g_d:{}'.format(gamma, gamma_dec))\n",
    "        print('----------------------')\n",
    "        i_f, u_f, rmse_tr, rmse_te = compute_mf_SGD(r_demeaned, nz_train, test_r_demeaned, nz_test,\n",
    "            verbose=True, #init_i_features=i_f, init_u_features=u_f,\n",
    "            k=k, i_lambda=i_lambda, u_lambda=u_lambda, gamma=gamma, gamma_dec=gamma_dec)\n",
    "\n",
    "        results_dict[et]={'k':k, 'u_lambda':u_lambda, 'i_lambda':i_lambda, 'gamma':gamma, 'gamma_dec':gamma_dec,\n",
    "                        'rmse_tr':rmse_tr, 'rmse_te':rmse_te, 'i_f':i_f, 'u_f':u_f}\n",
    "        et += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------\n",
      "k:20  u_l:1.6  i_l:0.8\n",
      "g:0.01  g_d:2.2\n",
      "----------------------\n",
      "0 - train_RMSE: 0.995245276060404.\n",
      "test RMSE: 1.0009318148881974.\n",
      "1 - train_RMSE: 0.9946764917990806.\n",
      "test RMSE: 1.0001412785857013.\n"
     ]
    }
   ],
   "source": [
    "parameters = [{'k':20, 'u_l':1.6, 'i_l':0.8, 'g':0.01, 'g_d':[2.2, 3.0, 3.5]},\n",
    "              {'k':31, 'u_l':1.4, 'i_l':0.6, 'g':0.015, 'g_d':[2.2, 3.0, 3.5]},\n",
    "              {'k':53, 'u_l':0.6, 'i_l':1.2, 'g':0.008, 'g_d':[2.2, 3.0, 3.5]},\n",
    "              {'k':64, 'u_l':0.2, 'i_l':1.35, 'g':0.008, 'g_d':[2.2, 3.0, 3.5]},\n",
    "              {'k':75, 'u_l':1.8, 'i_l':0.2, 'g':0.01,'g_d':[1.18, 1.2, 1.3]},\n",
    "              {'k':86, 'u_l':1.4, 'i_l':0.35,'g':0.007,'g_d':[1.72, 1.75]},\n",
    "              {'k':97, 'u_l':1.4, 'i_l':0.63, 'g':0.015, 'g_d':[2.2, 3.0, 3.5]},\n",
    "              {'k':108,'u_l':0.4, 'i_l':1.07, 'g':0.015, 'g_d':[1.8, 2.5, 3.2]},\n",
    "              {'k':120,'u_l':0.8, 'i_l':1.5, 'g':0.014, 'g_d':[1.75, 1.9, 2.5]}]\n",
    "\n",
    "results_dict = {}\n",
    "et=0\n",
    "i_f = None\n",
    "u_f = None\n",
    "np.random.seed(60)\n",
    "\n",
    "for param_dict in parameters:\n",
    "    i_f = None\n",
    "    u_f = None\n",
    "    k = param_dict['k']\n",
    "    u_lambda = param_dict['u_l']\n",
    "    i_lambda = param_dict['i_l']\n",
    "    gamma = param_dict['g']\n",
    "\n",
    "    for gamma_dec in param_dict['g_d']:\n",
    "        print('----------------------')\n",
    "        print('k:{}  u_l:{}  i_l:{}'.format(k, u_lambda, i_lambda))\n",
    "        print('g:{}  g_d:{}'.format(gamma, gamma_dec))\n",
    "        print('----------------------')\n",
    "        i_f, u_f, rmse_tr, rmse_te = compute_mf_SGD(r_demeaned, nz_train, test_r_demeaned, nz_test,\n",
    "            verbose=True, #init_i_features=i_f, init_u_features=u_f,\n",
    "            k=k, i_lambda=i_lambda, u_lambda=u_lambda, gamma=gamma, gamma_dec=gamma_dec)\n",
    "\n",
    "        results_dict[et]={'k':k, 'u_lambda':u_lambda, 'i_lambda':i_lambda, 'gamma':gamma, 'gamma_dec':gamma_dec,\n",
    "                        'rmse_tr':rmse_tr, 'rmse_te':rmse_te, 'i_f':i_f, 'u_f':u_f}\n",
    "        et += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a submission file"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Demean matrix and get feature vectors\n",
    "r_demeaned, global_mean, user_means, item_means = demean_matrix(ratings_csr, verbose=False)\n",
    "\n",
    "# Get non-zero elements\n",
    "nz_row, nz_col = ratings_csr.nonzero()\n",
    "nz_train = list(zip(nz_row, nz_col))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def compute_mf_SGD(r_demeaned, nz_train, k=20, gamma=0.01, gamma_dec=1.2,\n",
    "    u_lambda=0.5, i_lambda=0.5, max_iter=None, verbose=False, tol=5e-6,\n",
    "    init_u_features=None, init_i_features=None):\n",
    "    \"\"\"Compute matrix factorization by SGD.\n",
    "    Both 'data' and 'test_data' should be csr sparse matrices.\n",
    "    gamma_dec should be >=1\n",
    "    \"\"\"\n",
    "    if (max_iter is None):\n",
    "        steps = 50\n",
    "    else:\n",
    "        steps = max_iter\n",
    "    # Set seed\n",
    "    np.random.seed(988)\n",
    "    rand_u_features, rand_i_features = init_MF(r_demeaned, k)    \n",
    "    if (init_u_features is None):\n",
    "        u_features = rand_u_features\n",
    "    else:\n",
    "        u_features = init_u_features\n",
    "    if (init_i_features is None):\n",
    "        i_features = rand_i_features\n",
    "    else:\n",
    "        i_features = init_i_features\n",
    "    if verbose:\n",
    "        print(\"Starting matrix factorization with SGD...\")\n",
    "    rmse = 0\n",
    "    for step in range(steps):\n",
    "        # shuffle the training rating indices\n",
    "        #np.random.seed(988)\n",
    "        #np.random.shuffle(nz_train)\n",
    "        # Reduce learning rate\n",
    "        gamma /= gamma_dec\n",
    "        # Update item and user features\n",
    "        for i, u in nz_train:\n",
    "            i_f = i_features[i,:]\n",
    "            u_f = u_features[u,:]\n",
    "            e = r_demeaned[i, u] - np.dot(u_f,i_f)\n",
    "            # Obtain gradient\n",
    "            i_grad = e * u_f - i_lambda * i_f\n",
    "            u_grad = e * i_f - u_lambda * u_f\n",
    "            # Update user and item features\n",
    "            i_features[i,:] += gamma * i_grad\n",
    "            u_features[u,:] += gamma * u_grad\n",
    "        rmse_old = rmse\n",
    "        rmse = compute_error(r_demeaned, u_features, i_features, nz_train)\n",
    "        print(\"{} - train_RMSE: {}.\".format(step, rmse))\n",
    "        if(rmse_old - rmse < 0):\n",
    "            gamma_dec += .15\n",
    "            gamma /= gamma_dec\n",
    "        if(abs(rmse_old - rmse) < tol):\n",
    "            break\n",
    "    return i_features, u_features, rmse"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "(best_i_lambda, best_u_lambda, best_i_features, best_u_features, best_rmse) = results_lambda[0]\n",
    "for (i_lambda, u_lambda, i_features, u_features, rmse) in results_lambda:\n",
    "    if(rmse < best_rmse):\n",
    "        print('New best: {}'.format(rmse))\n",
    "        best_i_lambda = i_lambda\n",
    "        best_u_lambda = u_lambda\n",
    "        best_i_features = i_features\n",
    "        best_u_features = u_features\n",
    "        best_rmse = rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute feature vectors over all training dataset:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "i_features=None\n",
    "u_features=None\n",
    "best_rmse=90\n",
    "print('i_lambda={}  u_lambda={}  '.format(best_i_lambda, best_u_lambda))\n",
    "for gamma in np.logspace(-4,-1,4)[::-1]:\n",
    "    for gamma_dec in np.linspace(1.1,2.6,5)[::-1]:\n",
    "        print('----------------------------')\n",
    "        print('gamma={}  gamma_dec={}  '.format(gamma, gamma_dec))\n",
    "        print('----------------------------')\n",
    "        i_features, u_features, rmse = compute_mf_SGD(r_demeaned, nz_train, i_lambda=best_i_lambda,\n",
    "            u_lambda=best_u_lambda, verbose=True, init_i_features=i_features,\n",
    "            init_u_features=u_features, gamma=gamma, gamma_dec=gamma_dec)\n",
    "        if(rmse < best_rmse):\n",
    "            best_rmse = rmse\n",
    "            best_i_features_2 = i_features\n",
    "            best_u_features_2 = u_features"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "(test_rows, test_cols, test_vals) = sp.find(sample_submission_csr)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "with open('{dp}{fn}.csv'.format(dp=PREDICTION_PATH, fn='test_sgd_1'), 'w') as csvfile:\n",
    "    fieldnames = ['Id', 'Prediction']\n",
    "    writer = csv.DictWriter(csvfile, delimiter=\",\", fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for (i, u) in zip(test_rows, test_cols):\n",
    "        interaction = np.array([(best_u_features[u,:].dot(best_i_features[i,:]))\n",
    "        baseline = global_mean + user_means[u] + item_means[i]\n",
    "        pred_i_u = interaction + baseline\n",
    "        writer.writerow({'Id':'r{r}_c{c}'.format(r=i+1,c=u+1),'Prediction':pred_i_u})"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open('{dp}{fn}.csv'.format(dp=PREDICTION_PATH, fn='test_sgd_2'), 'w') as csvfile:\n",
    "    fieldnames = ['Id', 'Prediction']\n",
    "    writer = csv.DictWriter(csvfile, delimiter=\",\", fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for (i, u) in zip(test_rows, test_cols):\n",
    "        interaction = np.array([(best_u_features_2[u,:].dot(best_i_features_2[i,:]))\n",
    "        baseline = global_mean + user_means[u] + item_means[i]\n",
    "        pred_i_u = interaction + baseline\n",
    "        writer.writerow({'Id':'r{r}_c{c}'.format(r=i+1,c=u+1),'Prediction':pred_i_u})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
