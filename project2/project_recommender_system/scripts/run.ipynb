{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "PREDICTION_PATH = '../data/predictions/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datafile_methods.data_io import load_datasets, load_datasets_sur\n",
    "\n",
    "# Load datasets\n",
    "train, test, validation, ratings, sample_submission = load_datasets()\n",
    "train_sur, test_sur, validation_sur, ratings_sur, sample_submission_sur = load_datasets_sur()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from prediction_methods.baseline_model import model_baseline\n",
    "\n",
    "# Train on `train`. Predict for `test` and `validation` datasets\n",
    "model_baseline(train, test, True, validation_data=validation,\n",
    "    prediction_path=PREDICTION_PATH)\n",
    "\n",
    "# Train on entire training set. Predict for `submission` dataset\n",
    "model_baseline(ratings, sample_submission, False, prediction_path=PREDICTION_PATH)\n",
    "\n",
    "# Test RMSE of model_baseline: 1.0095626730173732\n",
    "#### BEFORE REFACTORING #######\n",
    "#test_rmse, pred_test = model_baseline(train, test, True, verbose=True)\n",
    "## Test RMSE of baseline using baseline: 1.0057078177840961\n",
    "#model_baseline(ratings_csr, sample_submission_csr, False, True, \"tmp\")\n",
    "## Achieves 1.00386 in Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix factorization with ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from prediction_methods.mf_als_model import model_mf_als\n",
    "\n",
    "# Train on `train`. Predict for `test` and `validation` datasets\n",
    "model_mf_als(train, test, True, validation_data=validation,\n",
    "    prediction_path=PREDICTION_PATH, k=20, lambda_u=.1, lambda_i=.1,\n",
    "    tol=1e-6, max_iter=100, fn_suffix='_k20')\n",
    "\n",
    "# Train on entire training set. Predict for `submission` dataset\n",
    "model_mf_als(ratings, sample_submission, False, prediction_path=PREDICTION_PATH,\n",
    "    k=20, lambda_u=.1, lambda_i=.1, tol=1e-6, max_iter=100, fn_suffix='_k20')\n",
    "\n",
    "## Before refactoring achieved 0.9878 in training\n",
    "## Other good param_combs are (k20, lambdas 0.095) and (k30, lambdas 0.095)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix factorization with SVD (scipy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from prediction_methods.mf_svd_model import model_mf_svd\n",
    "\n",
    "# Train on `train`. Predict for `test` and `validation` datasets\n",
    "model_mf_svd(train, test, True, validation_data=validation,\n",
    "    prediction_path=PREDICTION_PATH, k=16, library='scipy', fn_suffix='_scipy')\n",
    "\n",
    "# Train on entire training set. Predict for `submission` dataset\n",
    "model_mf_svd(ratings, sample_submission, False, prediction_path=PREDICTION_PATH,\n",
    "    k=16, library='scipy', fn_suffix='_scipy')\n",
    "\n",
    "## Before ref. achieved 0.99385 on test. It's better to average it with the next ones!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix factorization with SVD (sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train on `train`. Predict for `test` and `validation` datasets\n",
    "model_mf_svd(train, test, True, validation_data=validation, prediction_path=PREDICTION_PATH,\n",
    "    k=12, n_iter=50, library='sklearn', random_state=70, fn_suffix='_sklearn')\n",
    "\n",
    "# Train on entire training set. Predict for `submission` dataset\n",
    "model_mf_svd(ratings, sample_submission, False, prediction_path=PREDICTION_PATH,\n",
    "    k=12, n_iter=50, library='sklearn', random_state=70, fn_suffix='_sklearn')\n",
    "\n",
    "### Bef ref. achieved 0.99386 (approx) on test\n",
    "# Achieves 0.99082 in Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommend's ALS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from prediction_methods.recommend_model import model_mf_als_recommend\n",
    "n_item, n_user = ratings.shape\n",
    "\n",
    "# Train on `train`. Predict for `test` and `validation` datasets\n",
    "model_mf_als_recommend(train, test, True, n_user, n_item,\n",
    "    prediction_path=PREDICTION_PATH, validation_data=validation, k=20,\n",
    "    n_iter=50, reg=85e-3)\n",
    "\n",
    "# Train on entire training set. Predict for `submission` dataset\n",
    "model_mf_als_recommend(ratings, sample_submission, False,\n",
    "    n_user, n_item, prediction_path=PREDICTION_PATH,\n",
    "    k=20, n_iter=50, reg=85e-3)\n",
    "\n",
    "#Test RMSE of model_mf_als_recommend: 0.9975413590062877\n",
    "#0.98585 on Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprise models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* SlopeOne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from prediction_methods.surprise_models import model_slope_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_slope_one(train_sur, test_sur, True,\n",
    "    prediction_path=PREDICTION_PATH, validation_data=validation_sur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_slope_one(ratings_sur, sample_submission_sur, False,\n",
    "    prediction_path=PREDICTION_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* CoClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from prediction_methods.surprise_models import model_co_clustering\n",
    "model_co_clustering(train_sur, test_sur, True,\n",
    "    prediction_path=PREDICTION_PATH, validation_data=validation_sur,\n",
    "    n_cltr_u=75, n_cltr_i=3, n_epochs=100)\n",
    "\n",
    "model_co_clustering(ratings_sur, sample_submission_sur, False,\n",
    "    prediction_path=PREDICTION_PATH,\n",
    "    n_cltr_u=75, n_cltr_i=3, n_epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* KNN Baseline (user based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from prediction_methods.surprise_models import model_knn_baseline\n",
    "model_knn_baseline(train_sur, test_sur, True,\n",
    "    prediction_path=PREDICTION_PATH, validation_data=validation_sur,\n",
    "    k=300, min_k=20, name='pearson_baseline', user_based=True,\n",
    "    fn_suffix='_u')\n",
    "\n",
    "model_knn_baseline(ratings_sur, sample_submission_sur, False,\n",
    "    prediction_path=PREDICTION_PATH,\n",
    "    k=300, min_k=20, name='pearson_baseline', user_based=True,\n",
    "    fn_suffix='_u')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* KNN Baseline (item based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_knn_baseline(train_sur, test_sur, True,\n",
    "    prediction_path=PREDICTION_PATH, validation_data=validation_sur,\n",
    "    k=120, min_k=20, name='pearson_baseline', user_based=False,\n",
    "    fn_suffix='_i')\n",
    "\n",
    "model_knn_baseline(ratings_sur, sample_submission_sur, False,\n",
    "    prediction_path=PREDICTION_PATH,\n",
    "    k=120, min_k=20, name='pearson_baseline', user_based=False,\n",
    "    fn_suffix='_i')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load ratings for test and validation files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do (regularized?) linear regression on the test rating predictions to obtain best weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjust regularization for getting similar errors in test and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO\n",
    "#Also ask a TA if this is ok. Also, maybe I should not be calling the sets `test` and `validation`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load ratings for submission files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply previous weights to obtain a final submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
