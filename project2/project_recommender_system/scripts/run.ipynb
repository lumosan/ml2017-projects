{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data into training, test and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of nonzero elements in original data: 1176952\n",
      "Total number of nonzero elements in train data:    941562\n",
      "Total number of nonzero elements in test data:     235390\n",
      "Total number of nonzero elements in original data: 235390\n",
      "Total number of nonzero elements in train data:    117695\n",
      "Total number of nonzero elements in test data:     117695\n"
     ]
    }
   ],
   "source": [
    "from processing_methods.data_processing import load_data, split_data, save_csv\n",
    "\n",
    "# Load training dataset and example submission\n",
    "DATA_PATH = '../data/'\n",
    "ratings = load_data('{dp}data_train.csv'.format(dp=DATA_PATH))\n",
    "sample_submission = load_data('{dp}sample_submission.csv'.format(dp=DATA_PATH))\n",
    "\n",
    "# Split into training (0.8), test (0.1) and validation (0.1)\n",
    "all_r, train, test = split_data(ratings, min_num_ratings=0, p_test=0.2)\n",
    "all_r, test, validation = split_data(test, min_num_ratings=0, p_test=0.5)\n",
    "\n",
    "# Save files\n",
    "save_csv(train, header=False, prediction_path=DATA_PATH, filename='train_set')\n",
    "save_csv(test, header=False, prediction_path=DATA_PATH, filename='test_set')\n",
    "save_csv(validation, header=False, prediction_path=DATA_PATH, filename='validation_set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from processing_methods.data_processing import save_csv\n",
    "\n",
    "# Save files\n",
    "save_csv(train, header=False, prediction_path=DATA_PATH, filename='train_set')\n",
    "save_csv(test, header=False, prediction_path=DATA_PATH, filename='test_set')\n",
    "save_csv(validation, header=False, prediction_path=DATA_PATH, filename='validation_set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train on *train*. Predict for *test*, *validation* and *submission* datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from prediction_methods.baseline_model import model_baseline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
