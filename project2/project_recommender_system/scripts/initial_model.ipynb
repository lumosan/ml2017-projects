{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.io\n",
    "import scipy.sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from helpers import calculate_mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the Data\n",
    "`ratings` is a sparse matrix in the shape of (num_items, num_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of items: 10000, number of users: 1000\n"
     ]
    }
   ],
   "source": [
    "from helpers import load_data, preprocess_data\n",
    "\n",
    "DATA_PATH = '../data/'\n",
    "PREDICTION_PATH = '../data/predictions/'\n",
    "ratings = load_data('{dp}data_train.csv'.format(dp=DATA_PATH))\n",
    "#ratings = load_data('{dp}movielens100k.csv'.format(dp=DATA_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the number of ratings per movie and user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4/KEDgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f178ca3c908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min # of items per user = 8, min # of users per item = 3.\n"
     ]
    }
   ],
   "source": [
    "from plots import plot_raw_data\n",
    "\n",
    "num_items_per_user, num_users_per_item = plot_raw_data(ratings)\n",
    "\n",
    "print(\"min # of items per user = {}, min # of users per item = {}.\".format(\n",
    "        min(num_items_per_user), min(num_users_per_item)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the data into a train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_data(ratings, num_items_per_user, num_users_per_item,\n",
    "               min_num_ratings, p_test=0.1):\n",
    "    \"\"\"split the ratings to training data and test data.\n",
    "    Args:\n",
    "        min_num_ratings: \n",
    "            all users and items we keep must have at least min_num_ratings per user and per item. \n",
    "    \"\"\"\n",
    "    # set seed\n",
    "    np.random.seed(988)\n",
    "    \n",
    "    # select user and item based on the condition.\n",
    "    valid_users = np.where(num_items_per_user >= min_num_ratings)[0]\n",
    "    valid_items = np.where(num_users_per_item >= min_num_ratings)[0]\n",
    "    valid_ratings = ratings[valid_items, :][:, valid_users]\n",
    "    \n",
    "    # LIL is a convenient format for constructing sparse matrices\n",
    "    train = sp.lil_matrix(valid_ratings.shape)\n",
    "    test = sp.lil_matrix(valid_ratings.shape)\n",
    "    \n",
    "    valid_ratings_i, valid_ratings_u, valid_ratings_v = sp.find(valid_ratings)\n",
    "    valid_ratings_p_idx = np.random.permutation(range(len(valid_ratings_i)))\n",
    "    \n",
    "    n_test = int(p_test*len(valid_ratings_i))\n",
    "    \n",
    "    for idx in valid_ratings_p_idx[:n_test]:\n",
    "        test[valid_ratings_i[idx], valid_ratings_u[idx]] = valid_ratings_v[idx]\n",
    "        \n",
    "    for idx in valid_ratings_p_idx[n_test:]:\n",
    "        train[valid_ratings_i[idx], valid_ratings_u[idx]] = valid_ratings_v[idx]\n",
    "\n",
    "    print(\"Total number of nonzero elements in original data:{v}\".format(v=ratings.nnz))\n",
    "    print(\"Total number of nonzero elements in train data:{v}\".format(v=train.nnz))\n",
    "    print(\"Total number of nonzero elements in test data:{v}\".format(v=test.nnz))\n",
    "    \n",
    "    # convert to CSR for faster operations\n",
    "    return valid_ratings, train.tocsr(), test.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of nonzero elements in original data:1176952\n",
      "Total number of nonzero elements in train data:1059186\n",
      "Total number of nonzero elements in test data:117687\n"
     ]
    }
   ],
   "source": [
    "from plots import plot_train_test_data\n",
    "\n",
    "valid_ratings, train, test = split_data(\n",
    "    ratings, num_items_per_user, num_users_per_item, min_num_ratings=10, p_test=0.1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plot_train_test_data(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_division(a, b):\n",
    "    \"\"\"Computes element by element division.\n",
    "    If x/0 returns 0.\n",
    "    \"\"\"\n",
    "    # Raises error if vectors have different lengths\n",
    "    assert(len(a) == len(b))\n",
    "    \n",
    "    # Computes division\n",
    "    res = a.copy()\n",
    "    for i in range(len(a)):\n",
    "        if b[i] == 0:\n",
    "            res[i] = 0\n",
    "        else:\n",
    "            res[i] = a[i] / b[i]\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baselines "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ex10 functions"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "source": [
    "def baseline_global_mean(train, test):\n",
    "    \"\"\"Implements baseline method using the global mean.\"\"\"\n",
    "    # Compute global mean using training data\n",
    "    train_mean = train.sum() / train.count_nonzero()\n",
    "    \n",
    "    # Compute test error\n",
    "    test_mse = calculate_mse(test.data, train_mean)\n",
    "    test_rmse = np.sqrt(test_mse / len(test.data))\n",
    "    \n",
    "    print(\"Test RMSE of baseline using global mean: {e}\".format(e=test_rmse))\n",
    "\n",
    "\n",
    "def baseline_user_mean(train, test):\n",
    "    \"\"\"Implements baseline method using the user mean.\"\"\"\n",
    "    baseline_user_item_mean(train, test, 'user')\n",
    "\n",
    "    \n",
    "def baseline_item_mean(train, test):\n",
    "    \"\"\"Implements baseline method using the item mean.\"\"\"\n",
    "    baseline_user_item_mean(train, test, 'item')\n",
    "\n",
    "    \n",
    "def baseline_user_item_mean(train, test, mean):\n",
    "    \"\"\"Implements baseline method using either the user\n",
    "    or the item mean, as indicated in parameter mean.\"\"\"\n",
    "    if mean==\"user\":\n",
    "        flag = 1\n",
    "        inv_flag = 0\n",
    "    else:\n",
    "        flag = 0\n",
    "        inv_flag = 1\n",
    "    num = train.shape[flag]\n",
    "    \n",
    "    # Compute means using training data\n",
    "    train_ = sp.find(train)\n",
    "    counts = np.bincount(train_[flag], minlength=num)\n",
    "    sums = np.bincount(train_[flag], weights=train_[2], minlength=num)\n",
    "    means = compute_division(sums, counts)\n",
    "\n",
    "    # Do predictions\n",
    "    test_ = sp.find(test)\n",
    "    pred_test = test_[2].copy()\n",
    "    pred_test = 1.0 * pred_test\n",
    "    for x in range(num):\n",
    "        ys = test_[inv_flag][test_[flag]==x]\n",
    "        for y in ys:\n",
    "            pred_test[(test_[flag]==x) & (test_[inv_flag]==y)] = means[x]\n",
    "    \n",
    "    # Compute test error\n",
    "    test_mse = calculate_mse(test_[2], pred_test)\n",
    "    test_rmse = np.sqrt(test_mse / len(test_[2]))\n",
    "    \n",
    "    print(\"Test RMSE of baseline using {m} mean: {e}\".format(m=mean, e=test_rmse))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test implementations:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "baseline_global_mean(train, test)\n",
    "baseline_user_mean(train, test)\n",
    "baseline_item_mean(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Project functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Baseline rating\n",
    "def baseline_rating(data):\n",
    "    \"\"\"Implements baseline method using the global mean.\"\"\"\n",
    "    # Compute global mean using training data\n",
    "    data_mean = data.sum() / data.count_nonzero()\n",
    "    return data_mean\n",
    "\n",
    "\n",
    "# User or item specific effect\n",
    "def baseline_user_item_specific(data, mean):\n",
    "    \"\"\"Implements baseline method using either the user\n",
    "    or the item mean, as indicated in parameter mean.\"\"\"\n",
    "    if mean==\"user\":\n",
    "        flag = 1\n",
    "        inv_flag = 0\n",
    "    else:\n",
    "        flag = 0\n",
    "        inv_flag = 1\n",
    "\n",
    "    num = data.shape[flag]\n",
    "    \n",
    "    # Obtain data_deviations, which are the ratings minus global avg\n",
    "    global_mean = baseline_rating(data)\n",
    "    data_deviations = data.copy()\n",
    "    data_deviations.data -= global_mean\n",
    "    \n",
    "    # Compute means using training data\n",
    "    # get rows, columns and values for elements in data_deviations\n",
    "    data_rcv = sp.find(data_deviations)\n",
    "    counts = np.bincount(data_rcv[flag], minlength=num)\n",
    "    sums = np.bincount(data_rcv[flag], weights=data_rcv[2], minlength=num)\n",
    "    means = compute_division(sums, counts)\n",
    "\n",
    "    return means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict using global mean"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from helpers import create_csv_submission\n",
    "\n",
    "global_mean = bias_global_mean(ratings)\n",
    "user_means = bias_user_item_mean(ratings, 'user')\n",
    "item_means = bias_user_item_mean(ratings, 'item')\n",
    "\n",
    "sample_submission = np.genfromtxt('{dp}sample_submission.csv'.format(dp=DATA_PATH), delimiter=\",\", skip_header=1, dtype=str)\n",
    "ids = sample_submission[:,0]\n",
    "y_pred = np.full(len(ids), global_mean)\n",
    "\n",
    "create_csv_submission(ids, y_pred, '{pp}global_mean.csv'.format{pp=PREDICTION_PATH}) # Achieves 1.11785 in Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict using global, user and item means (baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first estimate the RMSE for our test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_baseline(data, test_data, test_flag, sub_flag=False, sub_filename=\"new_submission\"):\n",
    "    \"\"\"\n",
    "    If 'test_flag' is True, then 'data' should be the training dataset\n",
    "    'test_data' the test dataset. In this case sub_flag is ignored.\n",
    "    \n",
    "    If 'test_flag' is False and 'sub_flag' is True, then 'data' should be\n",
    "    the entire ratings dataset and 'test_data' should be a sample submission.\n",
    "    \n",
    "    Both 'data' and 'test_data' should be csr sparse matrices.\n",
    "    \"\"\"\n",
    "    assert test_flag or sub_flag, \"Specify a task\"\n",
    "    \n",
    "    global_mean = baseline_rating(data)\n",
    "    user_means = baseline_user_item_specific(data, 'user')\n",
    "    item_means = baseline_user_item_specific(data, 'item')\n",
    "\n",
    "    # Do predictions\n",
    "    num_items, num_users = test_data.shape\n",
    "    test_rcv = sp.find(test_data)\n",
    "    pred_test = test_rcv[2].copy()\n",
    "    pred_test = 1.0 * pred_test\n",
    "    for i in range(num_items):\n",
    "        for u in range(num_users):\n",
    "            pred_i_u = global_mean + user_means[u] + item_means[i]\n",
    "            pred_test[(test_rcv[0]==i) & (test_rcv[1]==u)] = pred_i_u\n",
    "    \n",
    "    if test_flag:\n",
    "        # Compute and print test error\n",
    "        test_mse = calculate_mse(test_rcv[2], pred_test)\n",
    "        test_rmse = np.sqrt(test_mse / len(test_rcv[2]))\n",
    "        print(\"Test RMSE of baseline using baseline: {e}\".format(e=test_rmse))\n",
    "\n",
    "    elif sub_flag:\n",
    "        create_csv_submission_spmat(pred_test, sub_filename)\n",
    "    \n",
    "    return pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE of baseline using baseline: 1.0057078177840961\n"
     ]
    }
   ],
   "source": [
    "pred_test = train_model_baseline(train, test, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we prepare the submission file training on all data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_csv_submission_spmat(prediction, name):\n",
    "    \"\"\"Creates an output file in csv format for submission to kaggle\n",
    "    Arguments: prediction (predicted rating, as a csr sparse matrix)\n",
    "               name (string name of .csv output file to be created)\n",
    "    \"\"\"\n",
    "    with open('{dp}{fn}.csv'.format(dp=PREDICTION_PATH, fn=name), 'w') as csvfile:\n",
    "        fieldnames = ['Id', 'Prediction']\n",
    "        writer = csv.DictWriter(csvfile, delimiter=\",\", fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for r, c, v in sp.find(pred_test):\n",
    "            writer.writerow({'Id':'r{r}_c{c}'.format(r=r,c=c),'Prediction':v})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of items: 10000, number of users: 1000\n"
     ]
    }
   ],
   "source": [
    "ratings_csr = ratings.tocsr()\n",
    "sample_submission = load_data('{dp}sample_submission.csv'.format(dp=DATA_PATH))\n",
    "sample_submission_csr = sample_submission.tocsr()\n",
    "\n",
    "train_model_baseline(ratings_csr, sample_submission_csr, False, True, \"baselines\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn the Matrix Factorization using SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize matrix factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_MF(train, num_features):\n",
    "    \"\"\"init the parameter for matrix factorization.\"\"\"\n",
    "    \n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO\n",
    "    # you should return:\n",
    "    #     user_features: shape = num_features, num_user\n",
    "    #     item_features: shape = num_features, num_item\n",
    "    # ***************************************************\n",
    "    return user_features, item_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the cost by the method of matrix factorization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_error(data, user_features, item_features, nz):\n",
    "    \"\"\"compute the loss (MSE) of the prediction of nonzero elements.\"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO\n",
    "    # calculate rmse (we only consider nonzero entries.)\n",
    "    # ***************************************************\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def matrix_factorization_SGD(train, test):\n",
    "    \"\"\"matrix factorization by SGD.\"\"\"\n",
    "    # define parameters\n",
    "    gamma = 0.01\n",
    "    num_features = 20   # K in the lecture notes\n",
    "    lambda_user = 0.1\n",
    "    lambda_item = 0.7\n",
    "    num_epochs = 20     # number of full passes through the train set\n",
    "    errors = [0]\n",
    "    \n",
    "    # set seed\n",
    "    np.random.seed(988)\n",
    "\n",
    "    # init matrix\n",
    "    user_features, item_features = init_MF(train, num_features)\n",
    "    \n",
    "    # find the non-zero ratings indices \n",
    "    nz_row, nz_col = train.nonzero()\n",
    "    nz_train = list(zip(nz_row, nz_col))\n",
    "    nz_row, nz_col = test.nonzero()\n",
    "    nz_test = list(zip(nz_row, nz_col))\n",
    "\n",
    "    print(\"learn the matrix factorization using SGD...\")\n",
    "    for it in range(num_epochs):        \n",
    "        # shuffle the training rating indices\n",
    "        np.random.shuffle(nz_train)\n",
    "        \n",
    "        # decrease step size\n",
    "        gamma /= 1.2\n",
    "        \n",
    "        for d, n in nz_train:\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # TODO\n",
    "        # do matrix factorization.\n",
    "        # ***************************************************\n",
    "        raise NotImplementedError\n",
    "\n",
    "        print(\"iter: {}, RMSE on training set: {}.\".format(it, rmse))\n",
    "        \n",
    "        errors.append(rmse)\n",
    "    # ***************************************************\n",
    "    # TODO\n",
    "    # evaluate the test error.\n",
    "    # ***************************************************\n",
    "    rmse = compute_error(test, user_features, item_features, nz_test)\n",
    "    print(\"RMSE on test data: {}.\".format(rmse))\n",
    "    raise NotImplementedError\n",
    "\n",
    "matrix_factorization_SGD(train, test)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn the Matrix Factorization using Alternating Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_user_feature(\n",
    "        train, item_features, lambda_user,\n",
    "        nnz_items_per_user, nz_user_itemindices):\n",
    "    \"\"\"update user feature matrix.\"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO\n",
    "    # update and return user feature.\n",
    "    # ***************************************************\n",
    "    raise NotImplementedError\n",
    "\n",
    "def update_item_feature(\n",
    "        train, user_features, lambda_item,\n",
    "        nnz_users_per_item, nz_item_userindices):\n",
    "    \"\"\"update item feature matrix.\"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO\n",
    "    # update and return item feature.\n",
    "    # ***************************************************\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from helpers import build_index_groups\n",
    "\n",
    "\n",
    "def ALS(train, test):\n",
    "    \"\"\"Alternating Least Squares (ALS) algorithm.\"\"\"\n",
    "    # define parameters\n",
    "    num_features = 20   # K in the lecture notes\n",
    "    lambda_user = 0.1\n",
    "    lambda_item = 0.7\n",
    "    stop_criterion = 1e-4\n",
    "    change = 1\n",
    "    error_list = [0, 0]\n",
    "    \n",
    "    # set seed\n",
    "    np.random.seed(988)\n",
    "\n",
    "    # init ALS\n",
    "    user_features, item_features = init_MF(train, num_features)\n",
    "    \n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO\n",
    "    # start you ALS-WR algorithm.\n",
    "    # ***************************************************\n",
    "    raise NotImplementedError\n",
    "\n",
    "ALS(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
