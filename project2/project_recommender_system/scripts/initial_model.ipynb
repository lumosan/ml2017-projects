{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.io\n",
    "import scipy.sparse as sp\n",
    "import csv\n",
    "\n",
    "import surprise\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from helpers import calculate_mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the Data\n",
    "`ratings` is a sparse matrix in the shape of (num_items, num_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import load_data, preprocess_data\n",
    "\n",
    "DATA_PATH = '../data/'\n",
    "PREDICTION_PATH = '../data/predictions/'\n",
    "#ratings = load_data('{dp}data_train.csv'.format(dp=DATA_PATH))\n",
    "R = load_data('{dp}movielens100k.csv'.format(dp=DATA_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the number of ratings per movie and user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from plots import plot_raw_data\n",
    "\n",
    "num_items_per_user, num_users_per_item = plot_raw_data(R)\n",
    "\n",
    "print(\"min # of items per user = {}, min # of users per item = {}.\".format(\n",
    "        min(num_items_per_user), min(num_users_per_item)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the data into a train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_data(ratings, num_items_per_user, num_users_per_item,\n",
    "               min_num_ratings, p_test=0.1, verbose=False):\n",
    "    \"\"\"split the ratings to training data and test data.\n",
    "    Args:\n",
    "        min_num_ratings: \n",
    "            all users and items we keep must have at least min_num_ratings per user and per item. \n",
    "    \"\"\"\n",
    "    # set seed\n",
    "    np.random.seed(988)\n",
    "    \n",
    "    # select user and item based on the condition.\n",
    "    valid_users = np.where(num_items_per_user >= min_num_ratings)[0]\n",
    "    valid_items = np.where(num_users_per_item >= min_num_ratings)[0]\n",
    "    valid_ratings = ratings[valid_items, :][:, valid_users]\n",
    "    \n",
    "    # LIL is a convenient format for constructing sparse matrices\n",
    "    train = sp.lil_matrix(valid_ratings.shape)\n",
    "    test = sp.lil_matrix(valid_ratings.shape)\n",
    "    \n",
    "    valid_ratings_i, valid_ratings_u, valid_ratings_v = sp.find(valid_ratings)\n",
    "    valid_ratings_p_idx = np.random.permutation(range(len(valid_ratings_i)))\n",
    "    \n",
    "    n_test = int(p_test*len(valid_ratings_i))\n",
    "    \n",
    "    for idx in valid_ratings_p_idx[:n_test]:\n",
    "        test[valid_ratings_i[idx], valid_ratings_u[idx]] = valid_ratings_v[idx]\n",
    "        \n",
    "    for idx in valid_ratings_p_idx[n_test:]:\n",
    "        train[valid_ratings_i[idx], valid_ratings_u[idx]] = valid_ratings_v[idx]\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Total number of nonzero elements in original data:{v}\".format(v=ratings.nnz))\n",
    "        print(\"Total number of nonzero elements in train data:{v}\".format(v=train.nnz))\n",
    "        print(\"Total number of nonzero elements in test data:{v}\".format(v=test.nnz))\n",
    "    \n",
    "    # convert to CSR for faster operations\n",
    "    return valid_ratings, train.tocsr(), test.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plots import plot_train_test_data\n",
    "\n",
    "valid_ratings, train, test = split_data(R, num_items_per_user,\n",
    "    num_users_per_item, min_num_ratings=10, p_test=0.7, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_train_test_data(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_division(a, b):\n",
    "    \"\"\"Computes element by element division.\n",
    "    If x/0 returns 0.\n",
    "    \"\"\"\n",
    "    # Raises error if vectors have different lengths\n",
    "    assert(len(a) == len(b))\n",
    "    \n",
    "    # Computes division\n",
    "    res = a.copy()\n",
    "    for i in range(len(a)):\n",
    "        if b[i] == 0:\n",
    "            res[i] = 0\n",
    "        else:\n",
    "            res[i] = a[i] / b[i]\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baselines "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ex10 functions"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "source": [
    "def baseline_global_mean(train, test):\n",
    "    \"\"\"Implements baseline method using the global mean.\"\"\"\n",
    "    # Compute global mean using training data\n",
    "    train_mean = train.sum() / train.count_nonzero()\n",
    "    \n",
    "    # Compute test error\n",
    "    test_mse = calculate_mse(test.data, train_mean)\n",
    "    test_rmse = np.sqrt(test_mse / len(test.data))\n",
    "    \n",
    "    print(\"Test RMSE of baseline using global mean: {e}\".format(e=test_rmse))\n",
    "\n",
    "\n",
    "def baseline_user_mean(train, test):\n",
    "    \"\"\"Implements baseline method using the user mean.\"\"\"\n",
    "    baseline_user_item_mean(train, test, 'user')\n",
    "\n",
    "    \n",
    "def baseline_item_mean(train, test):\n",
    "    \"\"\"Implements baseline method using the item mean.\"\"\"\n",
    "    baseline_user_item_mean(train, test, 'item')\n",
    "\n",
    "    \n",
    "def baseline_user_item_mean(train, test, mean):\n",
    "    \"\"\"Implements baseline method using either the user\n",
    "    or the item mean, as indicated in parameter mean.\"\"\"\n",
    "    if mean==\"user\":\n",
    "        flag = 1\n",
    "        inv_flag = 0\n",
    "    else:\n",
    "        flag = 0\n",
    "        inv_flag = 1\n",
    "    num = train.shape[flag]\n",
    "    \n",
    "    # Compute means using training data\n",
    "    train_ = sp.find(train)\n",
    "    counts = np.bincount(train_[flag], minlength=num)\n",
    "    sums = np.bincount(train_[flag], weights=train_[2], minlength=num)\n",
    "    means = compute_division(sums, counts)\n",
    "\n",
    "    # Do predictions\n",
    "    test_ = sp.find(test)\n",
    "    pred_test = test_[2].copy()\n",
    "    pred_test = 1.0 * pred_test\n",
    "    for x in range(num):\n",
    "        ys = test_[inv_flag][test_[flag]==x]\n",
    "        for y in ys:\n",
    "            pred_test[(test_[flag]==x) & (test_[inv_flag]==y)] = means[x]\n",
    "    \n",
    "    # Compute test error\n",
    "    test_mse = calculate_mse(test_[2], pred_test)\n",
    "    test_rmse = np.sqrt(test_mse / len(test_[2]))\n",
    "    \n",
    "    print(\"Test RMSE of baseline using {m} mean: {e}\".format(m=mean, e=test_rmse))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test implementations:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "baseline_global_mean(train, test)\n",
    "baseline_user_mean(train, test)\n",
    "baseline_item_mean(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Project functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Baseline rating\n",
    "def baseline_rating(R):\n",
    "    \"\"\"Implements baseline method for a ratings matrix R\n",
    "    using the global mean.\n",
    "    \"\"\"\n",
    "    # Compute global mean using training data\n",
    "    R_mean = R.sum() / R.count_nonzero()\n",
    "    return R_mean\n",
    "\n",
    "\n",
    "# User or item specific effect\n",
    "def baseline_user_item_specific(R, mean):\n",
    "    \"\"\"Implements baseline method  for a ratings matrix R\n",
    "    using either the user or the item mean,\n",
    "    as indicated in parameter mean.\n",
    "    \"\"\"\n",
    "    if mean==\"user\":\n",
    "        flag = 1\n",
    "        inv_flag = 0\n",
    "    else:\n",
    "        flag = 0\n",
    "        inv_flag = 1\n",
    "\n",
    "    num = R.shape[flag]\n",
    "    \n",
    "    # Obtain R_demeaned (ratings R minus global avg)\n",
    "    global_mean = baseline_rating(R)\n",
    "    R_demeaned = R.copy()\n",
    "    R_demeaned.data = 1.0 * R_demeaned.data\n",
    "    R_demeaned.data -= global_mean\n",
    "    \n",
    "    # Compute means using training data\n",
    "    # get rows, columns and values for elements in R_demeaned\n",
    "    data_rcv = sp.find(R_demeaned)\n",
    "    # compute means\n",
    "    counts = np.bincount(data_rcv[flag], minlength=num)\n",
    "    sums = np.bincount(data_rcv[flag], weights=data_rcv[2], minlength=num)\n",
    "    means = compute_division(sums, counts)\n",
    "\n",
    "    return means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict using global mean"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from helpers import create_csv_submission\n",
    "\n",
    "global_mean = baseline_rating(ratings)\n",
    "user_means = baseline_user_item_specific(ratings, 'user')\n",
    "item_means = baseline_user_item_specific(ratings, 'item')\n",
    "\n",
    "sample_submission = np.genfromtxt('{dp}sample_submission.csv'.format(dp=DATA_PATH), delimiter=\",\", skip_header=1, dtype=str)\n",
    "ids = sample_submission[:,0]\n",
    "y_pred = np.full(len(ids), global_mean)\n",
    "\n",
    "create_csv_submission(ids, y_pred, '{pp}global_mean.csv'.format{pp=PREDICTION_PATH}) # Achieves 1.11785 in Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict using global, user and item means (baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first estimate the RMSE for our test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_baseline(R, test_R, test_flag, sub_flag=False,\n",
    "    sub_filename=\"new_submission\", verbose=False):\n",
    "\n",
    "    \"\"\"If 'test_flag' is True, then 'R' should be the training dataset\n",
    "    'test_R' the test dataset. In this case sub_flag is ignored.\n",
    "    \n",
    "    If 'test_flag' is False and 'sub_flag' is True, then 'R' should be\n",
    "    the entire ratings dataset and 'test_R' should be a sample submission.\n",
    "    \n",
    "    Both 'R' and 'test_R' should be csr sparse matrices.\n",
    "    \"\"\"\n",
    "    assert test_flag or sub_flag, \"Specify a task\"\n",
    "    \n",
    "    global_mean = baseline_rating(R)\n",
    "    user_means = baseline_user_item_specific(R, 'user')\n",
    "    item_means = baseline_user_item_specific(R, 'item')\n",
    "    \n",
    "    (rows, cols, vals) = sp.find(test_R)\n",
    "    \n",
    "    if test_flag:        \n",
    "        # Do predictions\n",
    "        pred_test = vals.copy()\n",
    "        pred_test = 1.0 * pred_test\n",
    "\n",
    "        for (i, u) in zip(rows, cols):\n",
    "            pred_i_u = global_mean + user_means[u] + item_means[i]\n",
    "            pred_test[(rows==i) & (cols==u)] = pred_i_u\n",
    "\n",
    "        # Compute and print test error\n",
    "        test_mse = calculate_mse(vals, pred_test)\n",
    "        test_rmse = np.sqrt(test_mse / len(vals))\n",
    "        if verbose:\n",
    "            print(\"Test RMSE of baseline using baseline: {e}\".format(e=test_rmse)) \n",
    "        return test_rmse, pred_test\n",
    "\n",
    "    elif sub_flag:\n",
    "        # Directly write predictions to submission file\n",
    "        with open('{dp}{fn}.csv'.format(dp=PREDICTION_PATH, fn=sub_filename), 'w') as csvfile:\n",
    "            fieldnames = ['Id', 'Prediction']\n",
    "            writer = csv.DictWriter(csvfile, delimiter=\",\", fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            for (i, u) in zip(rows, cols):\n",
    "                pred_i_u = global_mean + user_means[u] + item_means[i]\n",
    "                writer.writerow({'Id':'r{r}_c{c}'.format(r=i+1,c=u+1),'Prediction':pred_i_u})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rmse, pred_test = model_baseline(train, test, True, verbose=True)\n",
    "# Test RMSE of baseline using baseline: 1.0057078177840963"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we prepare the submission file training on all data:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "ratings_csr = ratings.tocsr()\n",
    "sample_submission = load_data('{dp}sample_submission.csv'.format(dp=DATA_PATH))\n",
    "sample_submission_csr = sample_submission.tocsr()\n",
    "\n",
    "model_baseline(ratings_csr, sample_submission_csr, False, True, \"baselines_2\")\n",
    "# Achieves 1.00386 in Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def demean_matrix(R, add_constant, verbose=False):\n",
    "    \"\"\"Removes the global, user and item means from a matrix.\n",
    "    Returns the matrix and the computed means.\n",
    "    \"\"\"\n",
    "    num_rows, num_cols = R.shape\n",
    "    (rows, cols, vals) = sp.find(R)\n",
    "    \n",
    "    # Compute global, user and item means \n",
    "    global_mean = baseline_rating(R)\n",
    "    user_means = baseline_user_item_specific(R, 'user')\n",
    "    item_means = baseline_user_item_specific(R, 'item') \n",
    "    \n",
    "    # Substract the baseline of each element in 'R'\n",
    "    train_vals = vals.copy()\n",
    "    train_vals = 1.0 * train_vals\n",
    "\n",
    "    for (i, u) in zip(rows, cols):\n",
    "        baseline_i_u = global_mean + user_means[u] + item_means[i]\n",
    "        train_vals[(rows==i) & (cols==u)] -= baseline_i_u\n",
    "\n",
    "    # Get matrix\n",
    "    demeaned_R = sp.csr_matrix((train_vals, (rows, cols)),\n",
    "        shape=(num_rows, num_cols))\n",
    "    \n",
    "    demeaned_R = demeaned_R.todense() + add_constant\n",
    "    \n",
    "    if verbose:\n",
    "        print('---------------------------------------------')\n",
    "        print('          Completed demean_matrix!           ')\n",
    "        print('---------------------------------------------')\n",
    "    \n",
    "    return demeaned_R, global_mean, user_means, item_means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function is stupid, keeping it for future reference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_matrix_factorization(R, test_R, test_flag, sub_flag=False,\n",
    "    sub_filename=\"new_submission\", alpha=0, l1_ratio=0, shuffle=True, random_state=42,\n",
    "    verbose=False):\n",
    "\n",
    "    \"\"\"If 'test_flag' is True, then 'R' should be the training dataset and\n",
    "    'test_R' the test dataset. In this case sub_flag is ignored.\n",
    "    \n",
    "    If 'test_flag' is False and 'sub_flag' is True, then 'R' should be\n",
    "    the entire ratings dataset and 'test_R' should be a sample submission.\n",
    "    \n",
    "    Both 'R' and 'test_R' should be csr sparse matrices.\n",
    "    \"\"\"\n",
    "\n",
    "    assert test_flag or sub_flag, \"Specify a task\"\n",
    "\n",
    "    # Get matrix\n",
    "    add_constant = 0\n",
    "    demeaned_R, global_mean, user_means, item_means = demean_matrix(R, add_constant, verbose=verbose)\n",
    "    \n",
    "    # Create and  model - This one requires a non-negative matrix (add_constant=5)\n",
    "    #nmf_model = NMF(alpha=alpha, l1_ratio=l1_ratio, shuffle=shuffle, random_state=random_state)\n",
    "    #W = nmf_model.fit_transform(demeaned_R)\n",
    "    #H = nmf_model.components_\n",
    "    #W_csr = sp.csr_matrix(W)\n",
    "    #H_csr = sp.csr_matrix(H)\n",
    "    #pred_matrix = W_csr.dot(H_csr)\n",
    "    \n",
    "    if verbose:\n",
    "        print('Finished fitting model')\n",
    "\n",
    "    (test_rows, test_cols, test_vals) = sp.find(test)\n",
    "\n",
    "    if test_flag:        \n",
    "        # Do predictions\n",
    "        pred_test = test_vals.copy()\n",
    "        pred_test = 1.0 * pred_test\n",
    "        \n",
    "        for (i, u) in zip(test_rows, test_cols):\n",
    "            mat_fact_i_u = pred_matrix[i,u]\n",
    "            baseline_i_u = global_mean + user_means[u] + item_means[i]\n",
    "            pred_i_u = mat_fact_i_u + baseline_i_u - add_constant\n",
    "            \n",
    "            pred_test[(test_rows==i) & (test_cols==u)] = pred_i_u\n",
    "        \n",
    "        if verbose:\n",
    "            print('Finished predicting')\n",
    "\n",
    "        # Compute and print test error\n",
    "        test_mse = calculate_mse(test_vals, pred_test)\n",
    "        test_rmse = np.sqrt(test_mse / len(vals))\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"Test RMSE using baseline and matrix factorization: {e}\".format(e=test_rmse)) \n",
    "            print()\n",
    "            print('-----------------------------------------------')\n",
    "            print(' Completed test in model_matrix_factorization! ')    \n",
    "            print('-----------------------------------------------')\n",
    "            \n",
    "        return test_rmse, pred_test\n",
    "\n",
    "    elif sub_flag:\n",
    "        # Directly write predictions to submission file\n",
    "        with open('{dp}{fn}.csv'.format(dp=PREDICTION_PATH, fn=sub_filename), 'w') as csvfile:\n",
    "            fieldnames = ['Id', 'Prediction']\n",
    "            writer = csv.DictWriter(csvfile, delimiter=\",\", fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            \n",
    "            for (i, u) in zip(test_rows, test_cols):  \n",
    "                pred_i_u = pred_matrix[i,u]\n",
    "                baseline_i_u = global_mean + user_means[u] + item_means[i]\n",
    "                pred_i_u = mat_fact_i_u + baseline_i_u - add_constant\n",
    "                writer.writerow({'Id':'r{r}_c{c}'.format(r=i+1,c=u+1),'Prediction':pred_i_u})\n",
    "                \n",
    "        if verbose:\n",
    "            print('-----------------------------------------------------')\n",
    "            print(' Completed submission in model_matrix_factorization! ')    \n",
    "            print('-----------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Very simple example to try new functions on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5 2 0]\n",
      " [0 5 0]\n",
      " [1 4 0]\n",
      " [0 0 0]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nrows, ncols = (4,3)\n",
    "a=np.random.randint(0,7,(nrows,ncols))\n",
    "a[a>5]=0\n",
    "a=sp.csr_matrix(a)\n",
    "print(a.todense())\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Try with sklearn' s NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "a_demeaned, gm, um, im = demean_matrix(a, 5)\n",
    "print(a_demeaned)\n",
    "print()\n",
    "\n",
    "nmf_model = NMF(alpha=0, l1_ratio=0, shuffle=True, random_state=1)\n",
    "W = nmf_model.fit_transform(a_demeaned)\n",
    "H = nmf_model.components_\n",
    "\n",
    "pred_matrix=W.dot(H)\n",
    "print()\n",
    "print(W)\n",
    "print(H)\n",
    "\n",
    "pred_sol = np.full((nrows,ncols),1.0)\n",
    "\n",
    "for i in range(nrows):\n",
    "    for u in range(ncols):\n",
    "        mat_fact_i_u = pred_matrix[i,u]\n",
    "        baseline_i_u = gm + um[u] + im[i]\n",
    "        pred_i_u = mat_fact_i_u - 5 #+ baseline_i_u\n",
    "\n",
    "        pred_sol[i,u] = pred_i_u\n",
    "        #print('i{} u{} mf{} bl{} p{}'.format(i,u,mat_fact_i_u,baseline_i_u,pred_i_u))\n",
    "\n",
    "print()\n",
    "print(pred_sol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. With scipy's SVD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5 2 0]\n",
      " [0 5 0]\n",
      " [1 4 0]\n",
      " [0 0 0]]\n",
      "\n",
      "[[ 1.9        -1.76666667  0.        ]\n",
      " [ 0.         -0.26666667  0.        ]\n",
      " [-1.1         1.23333333  0.        ]\n",
      " [ 0.          0.          0.        ]]\n",
      "\n",
      "\n",
      "[[ 5.          2.          3.5       ]\n",
      " [ 4.6         5.          5.        ]\n",
      " [ 1.          4.          2.5       ]\n",
      " [ 3.          3.66666667  3.4       ]]\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "print(a.todense())\n",
    "print()\n",
    "\n",
    "a_demeaned, gm, um, im = demean_matrix(a, 0)\n",
    "print(a_demeaned)\n",
    "print()\n",
    "\n",
    "U, sigma, Vt = svds(a_demeaned, k = 2)\n",
    "sigma = np.diag(sigma)\n",
    "\n",
    "pred_matrix = np.dot(np.dot(U, sigma), Vt)\n",
    "pred_sol = np.full((nrows,ncols),1.0)\n",
    "\n",
    "for i in range(nrows):\n",
    "    for u in range(ncols):\n",
    "        mat_fact_i_u = pred_matrix[i,u]\n",
    "        baseline_i_u = gm + um[u] + im[i]\n",
    "        pred_i_u = mat_fact_i_u + baseline_i_u\n",
    "\n",
    "        pred_sol[i,u] = pred_i_u\n",
    "        #print('i{} u{} mf{} bl{} p{}'.format(i,u,mat_fact_i_u,baseline_i_u,pred_i_u))\n",
    "print()\n",
    "print(pred_sol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train some real models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratings_csr = ratings.tocsr()\n",
    "sample_submission = load_data('{dp}sample_submission.csv'.format(dp=DATA_PATH))\n",
    "sample_submission_csr = sample_submission.tocsr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(no models to train, sadly...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Factorization for Ex10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Factorization using SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some guy wanted to optimize running time, this is his code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://codereview.stackexchange.com/questions/35727/optimize-scipy-sparse-matrix-factorization-code-for-sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = self.model.shape[0] #no of users\n",
    "M = self.model.shape[1] #no of items\n",
    "self.p = np.random.rand(N, K)\n",
    "self.q = np.random.rand(M, K)\n",
    "rows,cols = self.model.nonzero()        \n",
    "for step in xrange(steps):\n",
    "    for u, i in zip(rows,cols):\n",
    "        e = self.model[u, i] - np.dot(self.p[u, :], self.q[i, :]) #calculate error for gradient\n",
    "        p_temp = learning_rate * ( e * self.q[i,:] - regularization * self.p[u,:])\n",
    "        self.q[i,:]+= learning_rate * ( e * self.p[u,:] - regularization * self.q[i,:])\n",
    "        self.p[u,:] += p_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize matrix factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_MF(train, num_features):\n",
    "    \"\"\"init the parameter for matrix factorization.\"\"\"\n",
    "    \n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO\n",
    "    # you should return:\n",
    "    #     user_features: shape = num_features, num_user\n",
    "    #     item_features: shape = num_features, num_item\n",
    "    # ***************************************************\n",
    "    return user_features, item_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the cost by the method of matrix factorization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_error(data, user_features, item_features, nz):\n",
    "    \"\"\"compute the loss (MSE) of the prediction of nonzero elements.\"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO\n",
    "    # calculate rmse (we only consider nonzero entries.)\n",
    "    # ***************************************************\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def matrix_factorization_SGD(train, test):\n",
    "    \"\"\"matrix factorization by SGD.\"\"\"\n",
    "    # define parameters\n",
    "    gamma = 0.01\n",
    "    num_features = 20   # K in the lecture notes\n",
    "    lambda_user = 0.1\n",
    "    lambda_item = 0.7\n",
    "    num_epochs = 20     # number of full passes through the train set\n",
    "    errors = [0]\n",
    "    \n",
    "    # set seed\n",
    "    np.random.seed(988)\n",
    "\n",
    "    # init matrix\n",
    "    user_features, item_features = init_MF(train, num_features)\n",
    "    \n",
    "    # find the non-zero ratings indices \n",
    "    nz_row, nz_col = train.nonzero()\n",
    "    nz_train = list(zip(nz_row, nz_col))\n",
    "    nz_row, nz_col = test.nonzero()\n",
    "    nz_test = list(zip(nz_row, nz_col))\n",
    "\n",
    "    print(\"learn the matrix factorization using SGD...\")\n",
    "    for it in range(num_epochs):        \n",
    "        # shuffle the training rating indices\n",
    "        np.random.shuffle(nz_train)\n",
    "        \n",
    "        # decrease step size\n",
    "        gamma /= 1.2\n",
    "        \n",
    "        for d, n in nz_train:\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # TODO\n",
    "        # do matrix factorization.\n",
    "        # ***************************************************\n",
    "        raise NotImplementedError\n",
    "\n",
    "        print(\"iter: {}, RMSE on training set: {}.\".format(it, rmse))\n",
    "        \n",
    "        errors.append(rmse)\n",
    "    # ***************************************************\n",
    "    # TODO\n",
    "    # evaluate the test error.\n",
    "    # ***************************************************\n",
    "    rmse = compute_error(test, user_features, item_features, nz_test)\n",
    "    print(\"RMSE on test data: {}.\".format(rmse))\n",
    "    raise NotImplementedError\n",
    "\n",
    "matrix_factorization_SGD(train, test)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn the Matrix Factorization using Alternating Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_user_feature(\n",
    "        train, item_features, lambda_user,\n",
    "        nnz_items_per_user, nz_user_itemindices):\n",
    "    \"\"\"update user feature matrix.\"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO\n",
    "    # update and return user feature.\n",
    "    # ***************************************************\n",
    "    raise NotImplementedError\n",
    "\n",
    "def update_item_feature(\n",
    "        train, user_features, lambda_item,\n",
    "        nnz_users_per_item, nz_item_userindices):\n",
    "    \"\"\"update item feature matrix.\"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO\n",
    "    # update and return item feature.\n",
    "    # ***************************************************\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from helpers import build_index_groups\n",
    "\n",
    "\n",
    "def ALS(train, test):\n",
    "    \"\"\"Alternating Least Squares (ALS) algorithm.\"\"\"\n",
    "    # define parameters\n",
    "    num_features = 20   # K in the lecture notes\n",
    "    lambda_user = 0.1\n",
    "    lambda_item = 0.7\n",
    "    stop_criterion = 1e-4\n",
    "    change = 1\n",
    "    error_list = [0, 0]\n",
    "    \n",
    "    # set seed\n",
    "    np.random.seed(988)\n",
    "\n",
    "    # init ALS\n",
    "    user_features, item_features = init_MF(train, num_features)\n",
    "    \n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO\n",
    "    # start you ALS-WR algorithm.\n",
    "    # ***************************************************\n",
    "    raise NotImplementedError\n",
    "\n",
    "ALS(train, test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
