import os
import csv
import scipy.sparse as sp
from datafile_methods.data_processing import load_data
from surprise.dataset import Reader
from surprise import Dataset


## Methods for loading data
def load_datasets(data_path='../data/'):
    """ Load all datasets """
    train = load_data('{dp}train_set.csv'.format(dp=data_path))
    test = load_data('{dp}test_set.csv'.format(dp=data_path))
    validation = load_data('{dp}validation_set.csv'.format(dp=data_path))
    ratings = load_data('{dp}data_train.csv'.format(dp=data_path))
    sample_submission = load_data('{dp}sample_submission.csv'.format(dp=data_path))
    return train, test, validation, ratings, sample_submission

def load_datasets_sur(data_path='../data/surprise/'):
    """Load all datasets for 'surprise' library"""
    # Define paths to dataset files
    tr_dp = os.path.expanduser('{}train_set.csv'.format(data_path))
    te_dp = os.path.expanduser('{}test_set.csv'.format(data_path))
    val_dp = os.path.expanduser('{}validation_set.csv'.format(data_path))
    rat_dp = os.path.expanduser('{}data_train.csv'.format(data_path))
    sub_dp = os.path.expanduser('{}sample_submission.csv'.format(data_path))

    # Define a Reader
    reader = Reader(line_format='item user rating', sep=',')

    # Load datasets
    train_ds = Dataset.load_from_file(tr_dp, reader=reader)
    test_ds = Dataset.load_from_file(te_dp, reader=reader)
    validation_ds = Dataset.load_from_file(val_dp, reader=reader)
    ratings_ds = Dataset.load_from_file(rat_dp, reader=reader)
    sample_submission_ds = Dataset.load_from_file(sub_dp, reader=reader)

    # Retrieve trainsets
    train = train_ds.build_full_trainset()
    ratings = ratings_ds.build_full_trainset()

    # Retrieve testsets
    test = test_ds.build_full_trainset().build_testset()
    validation = validation_ds.build_full_trainset().build_testset()
    sample_submission = sample_submission_ds.build_full_trainset().build_testset()

    return train, test, validation, ratings, sample_submission


## Methods for creating prediction Kaggle-style csv files
def save_csv(data_sp, prediction_path='', filename='new_file'):
    """Given a csr sparse matrix `data_sp` writes a Kaggle-style csv file"""
    with open('{dp}{fn}.csv'.format(dp=prediction_path, fn=filename), 'w') as csvfile:
        fieldnames = ['Id', 'Prediction']
        writer = csv.DictWriter(csvfile, delimiter=",", fieldnames=fieldnames)
        writer.writeheader()
        # Get non-zero elements
        (rows, cols, vals) = sp.find(data_sp)
        for (i, u, v) in zip(rows, cols, vals):
            writer.writerow({'Id':'r{r}_c{c}'.format(r=i+1,c=u+1),'Prediction':v})

def save_csv_rec(data_rec, pred_rec, prediction_path='',
    filename='new_file'):
    """Given an array `data_rec` and a vector of predictions
    `pred_rec` in the format required by library 'recommend',
    writes a Kaggle-style csv file
    """
    with open('{dp}{fn}.csv'.format(dp=prediction_path, fn=filename), 'w') as csvfile:
        fieldnames = ['Id', 'Prediction']
        writer = csv.DictWriter(csvfile, delimiter=",", fieldnames=fieldnames)
        writer.writeheader()
        for e in range(data_rec.shape[0]):
            writer.writerow({'Id':'r{r}_c{c}'.format(r=data_rec[e,1]+1,
                c=data_rec[e,0]+1),'Prediction':pred_rec[e]})

def save_csv_sur(data_pred, prediction_path='', filename='new_file'):
    """Given a list `data_pred` in the format generated by library
    'surprise', writes a Kaggle-style csv file
    """
    with open('{dp}{fn}.csv'.format(dp=prediction_path, fn=filename), 'w') as csvfile:
        fieldnames = ['Id', 'Prediction']
        writer = csv.DictWriter(csvfile, delimiter=",", fieldnames=fieldnames)
        writer.writeheader()
        for p in data_pred:
            writer.writerow({'Id':'r{r}_c{c}'.format(r=p.iid, c=p.uid),
                             'Prediction':p.est})
