{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing data using Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IN_TEST_DATA_PATH = '../data/test.csv'\n",
    "IN_TRAIN_DATA_PATH = '../data/train.csv'\n",
    "\n",
    "OUT_TEST_DATA_PATH = '../data/test_fixed.csv'\n",
    "OUT_TRAIN_DATA_PATH = '../data/train_fixed.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFrame:\n",
    "    '''\n",
    "    This class is used as a data-container,\n",
    "    representeing column-organized information\n",
    "    read from csv files.\n",
    "    '''\n",
    "    column_labels = {}\n",
    "    data = None\n",
    "    \n",
    "    def __init__(self, csv_path=None):\n",
    "        \n",
    "        # Leave the labels and data empty if the path is None\n",
    "        if csv_path is None:\n",
    "            return\n",
    "        \n",
    "        temp_data = None\n",
    "        \n",
    "        with open(csv_path) as csv_file:\n",
    "            csv_reader =  csv.reader(csv_file)\n",
    "            n_rows = sum(1 for row in csv_reader)\n",
    "        \n",
    "            # Reset reader's head pointer\n",
    "            csv_file.seek(0)\n",
    "            \n",
    "            for row_idx, row in enumerate(csv_reader):\n",
    "                if (row_idx == 0):\n",
    "                    \n",
    "                    # Fill in dictionary with (column_name:column_index)\n",
    "                    for column_idx, column_label in enumerate(row):\n",
    "                        self.column_labels[column_label] = column_idx\n",
    "                    temp_data = [[0 for x in range(n_rows-1)] for y in range(len(self.column_labels))]\n",
    "                else:\n",
    "                    \n",
    "                    # Fill data in a column-oriented fashion\n",
    "                    for column_idx, column_value in enumerate(row):\n",
    "                        temp_data[column_idx][row_idx-1] = column_value\n",
    "        \n",
    "        # Store all the data into an 'ndarray'\n",
    "        self.data = np.array(temp_data)\n",
    "    \n",
    "    # targets have to be labels, not indices\n",
    "    def get_columns(self, targets=None):\n",
    "        '''\n",
    "        Returns a copy the desired columns' data as a \n",
    "        list of Column objects.\n",
    "        '''\n",
    "        columns = []\n",
    "        \n",
    "        if targets is not None:\n",
    "            if all(isinstance(label, str) for label in targets):\n",
    "                columns = [Column(label, self.data[self.column_labels[label],:]) for label in targets]\n",
    "        else:\n",
    "            columns = [Column(label, self.data[self.column_labels[label],:]) for label in self.column_labels]\n",
    "            \n",
    "        return columns\n",
    "    \n",
    "    # 'at' cannot have repeated values\n",
    "    def insert(self, columns, at):\n",
    "        '''\n",
    "        Returns a new DataFrame with newly\n",
    "        inserted columns, at a designated index.\n",
    "        '''\n",
    "        dataframe_clone = self.__clone()\n",
    "        \n",
    "        # Zip columns and their desired indexes together for iteration\n",
    "        col_idx_zipped = sorted(zip(columns, at), key = lambda t: t[1])\n",
    "        \n",
    "        # Create a new dictionary of labels to append\n",
    "        new_labels = dict(col_idx_zipped)\n",
    "        new_labels = {column.label: idx for column, idx in col_idx_zipped}\n",
    "        \n",
    "        # Insert the columns' data\n",
    "        for column, idx in col_idx_zipped:\n",
    "            dataframe_clone.data = np.insert(dataframe_clone.data, idx, copy.deepcopy(column.values), 0)\n",
    "        \n",
    "        # Apply index offset where needed\n",
    "        for column, idx in col_idx_zipped:\n",
    "            offset_column_labels = {}\n",
    "            for k, v in dataframe_clone.column_labels.items():\n",
    "                offset_column_labels[k] = (v + 1) if (v >= idx) else v\n",
    "            dataframe_clone.column_labels = offset_column_labels\n",
    "           \n",
    "        # Append the new labels to previously existing ones\n",
    "        dataframe_clone.column_labels = {**dataframe_clone.column_labels, **new_labels}\n",
    "        \n",
    "        return dataframe_clone\n",
    "    \n",
    "    # target_axix=0 is columns, target_axix=1 is rows\n",
    "    def drop(self, targets, target_axis=0):\n",
    "        '''\n",
    "        Returns a new DataFrame without the\n",
    "        dropped columns/rows.\n",
    "        '''\n",
    "        dataframe_clone = self.__clone()\n",
    "        dropable_indexes = []\n",
    "        \n",
    "        # All elements in the list are indexes\n",
    "        if all(isinstance(index, int) for index in targets):\n",
    "            dropable_indexes = targets\n",
    "            dropable_keys = [key for key in dataframe_clone.column_labels if dataframe_clone.column_labels[key] in targets]\n",
    "            dataframe_clone.data = np.delete(dataframe_clone.data, [dataframe_clone.column_labels.pop(label) for label in dropable_keys], axis=target_axis)\n",
    "        \n",
    "        # All elements in the list are labels\n",
    "        elif all(isinstance(label, str) for label in targets) and target_axis == 0:\n",
    "            dropable_indexes = [self.column_labels[label] for label in targets]\n",
    "            dataframe_clone.data = np.delete(dataframe_clone.data, [dataframe_clone.column_labels.pop(label) for label in targets], axis=target_axis)\n",
    "        \n",
    "        # Non-expected parameters, just return the whole DataFrame\n",
    "        else:\n",
    "            return dataframe_clone\n",
    "        \n",
    "        # Apply index offset where needed\n",
    "        dropable_indexes.sort(reverse=True)\n",
    "        for idx in dropable_indexes:\n",
    "            offset_column_labels = {}\n",
    "            for k, v in dataframe_clone.column_labels.items():\n",
    "                offset_column_labels[k] = (v - 1) if (v >= idx) else v\n",
    "            dataframe_clone.column_labels = copy.deepcopy(offset_column_labels)\n",
    "        \n",
    "        return dataframe_clone\n",
    "    \n",
    "    def replace(self, existing_value, new_value):\n",
    "        '''\n",
    "        Replaces all occurrences of a given value,\n",
    "        in the DataFrame, witha new specified value.\n",
    "        '''\n",
    "        dataframe_clone = self.__clone()\n",
    "        if np.isnan(existing_value):\n",
    "            dataframe_clone.data[np.isnan(dataframe_clone.data)] = new_value\n",
    "        else:\n",
    "            dataframe_clone.data[dataframe_clone.data == existing_value] = new_value\n",
    "        return dataframe_clone\n",
    "    \n",
    "    def mean(self):\n",
    "        '''\n",
    "        Returns a new DataFrame with the columns'\n",
    "        mean values.\n",
    "        '''\n",
    "        mean_df = DataFrame()\n",
    "        mean_df.column_labels = copy.deepcopy(self.column_labels)\n",
    "        \n",
    "        columns = self.get_columns()\n",
    "        \n",
    "        temp_data = [[0 for x in range(1)] for y in range(len(self.column_labels))]\n",
    "        for column in columns:\n",
    "            temp_data[self.column_labels[column.label]][0] = column.mean()\n",
    "            \n",
    "        mean_df.data = np.array(temp_data)\n",
    "        \n",
    "        return mean_df\n",
    "    \n",
    "    def std(self):\n",
    "        '''\n",
    "        Returns a new DataFrame with the columns'\n",
    "        stadard deviation values.\n",
    "        '''\n",
    "        std_df = DataFrame()\n",
    "        std_df.column_labels = copy.deepcopy(self.column_labels)\n",
    "        \n",
    "        columns = self.get_columns()\n",
    "        \n",
    "        temp_data = [[0 for x in range(1)] for y in range(len(self.column_labels))]\n",
    "        for column in columns:\n",
    "            temp_data[self.column_labels[column.label]][0] = column.std()\n",
    "            \n",
    "        std_df.data = np.array(temp_data)\n",
    "        \n",
    "        return std_df\n",
    "    \n",
    "    def normalize(self):\n",
    "        '''\n",
    "        Returns a DataFrame with column-based\n",
    "        normalization.\n",
    "        '''\n",
    "        normalized_df = DataFrame()\n",
    "        normalized_df.column_labels = copy.deepcopy(self.column_labels)\n",
    "        \n",
    "        temp_data = [[0 for x in range(len(self.data[0,:]))] for y in range(len(self.column_labels))]\n",
    "        for column in self.get_columns():\n",
    "            temp_data[normalized_df.column_labels[column.label]] = column.normalize().values\n",
    "        \n",
    "        normalized_df.data = np.array(temp_data)\n",
    "        \n",
    "        return normalized_df\n",
    "    \n",
    "    def corr(self):\n",
    "        '''\n",
    "        Returns a DataFrame with the correlation\n",
    "        coeficients between all of the columns.\n",
    "        '''\n",
    "        corr_df = DataFrame()\n",
    "        corr_df.column_labels = copy.deepcopy(self.column_labels)\n",
    "        corr_df.data = np.corrcoef(self.data)\n",
    "        \n",
    "        return corr_df\n",
    "    \n",
    "    def set_type(self, target_type):\n",
    "        '''\n",
    "        Attempts to change the DataFrame's data\n",
    "        type to a single type (target_type). The\n",
    "        returned DataFrame is a copy of 'self'.\n",
    "        '''\n",
    "        dataframe_clone = self.__clone()\n",
    "        dataframe_clone.data = dataframe_clone.data.astype(target_type)\n",
    "        return dataframe_clone\n",
    "    \n",
    "    def __clone(self):\n",
    "        '''\n",
    "        Creates and returns a clone of the current\n",
    "        DataFrame object (creating a deep copy of\n",
    "        all its components).\n",
    "        '''\n",
    "        dataframe_clone = copy.deepcopy(self)\n",
    "        dataframe_clone.column_labels = copy.deepcopy(self.column_labels)\n",
    "        dataframe_clone.data = copy.deepcopy(self.data)\n",
    "        return dataframe_clone\n",
    "    \n",
    "    def __repr__(self):\n",
    "        '''\n",
    "        Default class' representation.\n",
    "        '''\n",
    "        return str(self)\n",
    "    \n",
    "    def __str__(self):\n",
    "        '''\n",
    "        Default class' string representation.\n",
    "        '''\n",
    "        max_columns = min(6, len(self.column_labels.keys()))\n",
    "        max_rows = min(8, len(self.data[0,:]))\n",
    "        max_string_size = 13\n",
    "        final_string = '| '\n",
    "        \n",
    "        # Add the schema to the top\n",
    "        for idx, label in enumerate(sorted(self.column_labels.keys(), key = lambda t: self.column_labels[t])):\n",
    "            if (idx < max_columns):\n",
    "                label_rep = label if (len(label) <= max_string_size) else label[:max_string_size-3] + '...'\n",
    "                final_string += label_rep.rjust(max_string_size) + ' | '\n",
    "            elif (idx == max_columns):\n",
    "                final_string += '...'\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        final_string += '\\n'\n",
    "        final_string += '-' * (max_string_size * max_columns + (max_columns + 1) * 3)\n",
    "        \n",
    "        # Add the first rows as preview\n",
    "        for i in range(max_rows):\n",
    "            final_string += '\\n| '\n",
    "            for idx, value in enumerate(self.data[:,i]):\n",
    "                if (idx < max_columns):\n",
    "                    value_rep = str(value) if (len(str(value)) <= max_string_size) else str(value)[:max_string_size-3] + '...'\n",
    "                    final_string += value_rep.rjust(max_string_size) + ' | '\n",
    "                elif (idx == max_columns):\n",
    "                    final_string += '...'\n",
    "                else:\n",
    "                    break\n",
    "        \n",
    "        if (len(self.data[0,:]) > max_rows):\n",
    "            final_string += '\\n(...)\\n'\n",
    "        else:\n",
    "            final_string += '\\n'\n",
    "        \n",
    "        return final_string\n",
    "    \n",
    "class Column:\n",
    "    '''\n",
    "    This class is meant as single column's\n",
    "    data representation.\n",
    "    '''\n",
    "    label = None\n",
    "    values = None\n",
    "    \n",
    "    def __init__(self, label, values):\n",
    "        self.label = label\n",
    "        self.values = values\n",
    "        \n",
    "    def mean(self):\n",
    "        '''\n",
    "        Calculates the column's values mean,\n",
    "        while ignoring NaNs.\n",
    "        '''\n",
    "        return np.nanmean(self.values)\n",
    "    \n",
    "    def std(self):\n",
    "        '''\n",
    "        Calculates the column's values stadrad\n",
    "        deviation, while ignoring NaNs.\n",
    "        '''\n",
    "        return np.nanstd(self.values)\n",
    "    \n",
    "    def normalize(self):\n",
    "        '''\n",
    "        Returns a column with normalized values.\n",
    "        '''\n",
    "        column_clone = self.__clone()\n",
    "        column_clone.values = column_clone.values - column_clone.mean()\n",
    "        column_clone.values = column_clone.values / column_clone.std()\n",
    "        return column_clone\n",
    "    \n",
    "    def nonan(self):\n",
    "        '''\n",
    "        Returns an Column with all the non NaN\n",
    "        values.\n",
    "        '''\n",
    "        column_clone = self.__clone()\n",
    "        column_clone.values = column_clone.values[~np.isnan(column_clone.values)]\n",
    "        return column_clone\n",
    "    \n",
    "    def __clone(self):\n",
    "        column_clone = copy.deepcopy(self)\n",
    "        column_clone.label = self.label\n",
    "        column_clone.values = copy.deepcopy(self.values)\n",
    "        return column_clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df = DataFrame(IN_TEST_DATA_PATH)\n",
    "train_df = DataFrame(IN_TRAIN_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store 'Id' and 'Prediction' columns\n",
    "test_id_column, test_prediction_column = test_df.get_columns(['Id', 'Prediction'])\n",
    "train_id_column, train_prediction_column = train_df.get_columns(['Id', 'Prediction'])\n",
    "\n",
    "# Drop 'Id' and 'Prediction' columns and replace '-999' with 'NaN'\n",
    "test_df = test_df.drop(['Id', 'Prediction']).set_type(float).replace(-999.0, float('NaN'))\n",
    "train_df = train_df.drop(['Id', 'Prediction']).set_type(float).replace(-999.0, float('NaN'))\n",
    "\n",
    "# Create correlation matrices\n",
    "test_corr_df = test_df.replace(float('NaN'), 0.0).corr()\n",
    "train_corr_df = train_df.replace(float('NaN'), 0.0).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df.replace(float('NaN'), 0.0).corr().get_columns())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "|  DER_mass_MMC | DER_mass_t... |  DER_mass_vis |      DER_pt_h | DER_deltae... | DER_mass_j... | ...\n",
       "---------------------------------------------------------------------------------------------------\n",
       "| 121.871729343 | 49.2583872444 | 81.1223376772 | 57.8290937019 | 2.40501628365 | 372.355428652 | ..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "|  DER_mass_MMC | DER_mass_t... |  DER_mass_vis |      DER_pt_h | DER_deltae... | DER_mass_j... | ...\n",
       "---------------------------------------------------------------------------------------------------\n",
       "| 56.7853497841 |  35.393433862 | 40.4739995151 | 63.3043943928 |  1.7426863849 | 398.470091756 | ..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get NaN count for each column\n",
    "nan_count = {}\n",
    "for column in test_df.get_columns():\n",
    "    nan_count[column.label] = len(column.values) - len(column.nonan().values)\n",
    "    \n",
    "# Get columns sorted by NaN count\n",
    "sorted_nan_count = sorted(nan_count, key=nan_count.get)\n",
    "\n",
    "# Pick 1/3 worst columns to remove\n",
    "target_columns = sorted_nan_count[int(2 * len(sorted_nan_count) / 3):]\n",
    "\n",
    "# Drop columns from DataFrames\n",
    "test_df = test_df.drop(target_columns)\n",
    "train_df = train_df.drop(target_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing dataframes\n",
    "test_df = test_df.normalize()\n",
    "train_df = train_df.normalize()\n",
    "\n",
    "# Replacing NaNs with 0s\n",
    "test_df = test_df.replace(float('NaN'), 0.0)\n",
    "train_df = train_df.replace(float('NaN'), 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add 'Id' and 'Prediction' columns back into the dataframes\n",
    "test_df = test_df.set_type(str).insert([test_id_column, test_prediction_column], [0, 1])\n",
    "train_df = train_df.set_type(str).insert([train_id_column, train_prediction_column], [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "|            Id |    Prediction |  DER_mass_MMC | DER_mass_t... |  DER_mass_vis |      DER_pt_h | ...\n",
       "---------------------------------------------------------------------------------------------------\n",
       "|        350000 |             ? |           0.0 | 0.85695592... | -1.4134095... | -0.8655496... | ...\n",
       "|        350001 |             ? | -0.2724950... | 0.51511285... | 0.16866784... | -0.1237685... | ...\n",
       "|        350002 |             ? | -0.0718095... | 0.19686173... | 0.37643085... | -0.8481574... | ...\n",
       "|        350003 |             ? | 0.24635351... | -0.5270578... | 0.39940857... | -0.7696952... | ...\n",
       "|        350004 |             ? | -0.8402295... | 0.94688785... | -0.5532277... | 0.50260185... | ...\n",
       "|        350005 |             ? | -0.4607302... | 1.26886848... | -0.3667128... | -0.6809968... | ...\n",
       "|        350006 |             ? | -0.6352647... | -0.0056334... | -0.3703942... | -0.3278618... | ...\n",
       "|        350007 |             ? | 5.41339045... | 0.72890957... | 3.79225340... | 0.20835688... | ...\n",
       "(...)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "|            Id |    Prediction |  DER_mass_MMC | DER_mass_t... |  DER_mass_vis |      DER_pt_h | ...\n",
       "---------------------------------------------------------------------------------------------------\n",
       "|        100000 |             s | 0.28991352... | 0.06833196... | 0.40768027... | -0.4699662... | ...\n",
       "|        100001 |             b | 0.68202130... | 0.55250482... | 0.54013641... | -0.1531674... | ...\n",
       "|        100002 |             b |           0.0 | 3.19515552... | 1.09655997... | -0.3497096... | ...\n",
       "|        100003 |             b | 0.38476846... | 0.91037909... | -0.0058532... | -0.9030156... | ...\n",
       "|        100004 |             b | 0.94253641... | -0.9145561... | 1.31336873... | -0.6518042... | ...\n",
       "|        100005 |             b | -0.5604823... | -1.0097611... | -0.5396456... | 0.91819227... | ...\n",
       "|        100006 |             s | 0.46939616... | -0.5765433... | 0.65150440... | 0.75773495... | ...\n",
       "|        100007 |             s | 0.57693914... | -1.0983738... | 0.33143471... | -0.4512875... | ...\n",
       "(...)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
